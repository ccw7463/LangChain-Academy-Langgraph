{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph state ë‹¤ë£¨ê¸°\n",
    "\n",
    "- build í•œ ê·¸ë˜í”„ì— ì ‘ê·¼í•´ì„œ ë‹¤ë£°ìˆ˜ ìˆëŠ” ëª‡ê°€ì§€ ë©”ì„œë“œ \n",
    "\n",
    "    - get_graph : ê·¸ë˜í”„ ë…¸ë“œ, ì—£ì§€ ì •ë³´ í™•ì¸\n",
    "\n",
    "    - get_state : ê·¸ë˜í”„ ìƒíƒœ ì •ë³´í™•ì¸ (config í•„ìˆ˜)\n",
    "\n",
    "        - ì…ë ¥ : `RunnableConfig` í•„ìˆ˜\n",
    "\n",
    "        - ë¦¬í„´ê°’ : ***StateSnapshot***\n",
    "\n",
    "    - get_state_history : ê·¸ë˜í”„ ìƒíƒœ ì •ë³´ íˆìŠ¤í† ë¦¬ í™•ì¸ (config í•„ìˆ˜)\n",
    "\n",
    "        - ì…ë ¥ : `RunnableConfig` í•„ìˆ˜\n",
    "\n",
    "        - ë¦¬í„´ê°’ : ***StateSnapshot*** ì œë„ˆë ˆì´í„° (ë°˜ë³µë¬¸ìœ¼ë¡œ ì ‘ê·¼ í•„ìš”)\n",
    "        \n",
    "    - update_state : ê·¸ë˜í”„ ìƒíƒœì •ë³´ ì—…ë°ì´íŠ¸\n",
    "        \n",
    "        - ì…ë ¥ : `RunnableConfig` í•„ìˆ˜\n",
    "\n",
    "        - ë¦¬í„´ê°’ : `RunnableConfig`  \n",
    "\n",
    "- ì°¸ê³ \n",
    "\n",
    "    - https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.state.CompiledStateGraph.aget_state\n",
    "    \n",
    "    - https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/#interacting-with-the-agent\n",
    "\n",
    "- ì•Œì•„ë‘˜ ë‚´ìš© âœ…\n",
    "\n",
    "    - ë©€í‹°í„´ì„ ìœ„í•´ ShortTermMemoryë¥¼ ì‚¬ìš©í• ë•Œ, config ì •ë³´ë¥¼ ë„£ì–´ì£¼ê²Œ ë¨.\n",
    "    \n",
    "    - graph ì‹¤í–‰ì‹œ í•´ë‹¹ config ì •ë³´ì— ëŒ€í•´ `checkpoint_ns, checkpoint_id` ê°€ ìƒì„±ë¨\n",
    "\n",
    "    - ê·¸ë˜í”„ì—ì„œ ë…¸ë“œê°€ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë ë•Œ, ì£¼ê³  ë°›ëŠ” ìƒíƒœì •ë³´(state)ì— ëŒ€í•œ ì¸ì‹/êµ¬ë³„ì€ `checkpoint_id` ë¡œ ìˆ˜í–‰í•¨.\n",
    "\n",
    "        - ì°¸ê³ ë¡œ `state['messages']`ì— ìˆëŠ” idê°’ê³¼ ë³„ê°œì´ë‹¤.\n",
    "\n",
    "        - ì¦‰ ìš”ì•½í•˜ë©´\n",
    "\n",
    "            - `messages`ì— ìˆëŠ” `id` ê°’ì€ `ë©”ì‹œì§€ê°„ ì¸ì‹ì„ ìœ„í•œê²ƒ`\n",
    "\n",
    "            - `config`ì— ìˆëŠ” `checkpoint_id` ëŠ” ê·¸ë˜í”„ì˜ `ë…¸ë“œê°„ state êµ¬ë³„ì„ ìœ„í•œê²ƒ`\n",
    "\n",
    "    - ì•„ë˜ ì˜ˆì‹œ ì°¸ê³  : 3ë²ˆ ëŒ€í™”í•œí›„ ë§ˆì§€ë§‰ ***ìƒíƒœì •ë³´(snapshot)*** ë¥¼ ì¶”ì¶œí•œ ê²ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  \"StateSnapshot\": {\n",
    "    \"values\": {\n",
    "      \"messages\": [{\"HumanMessage\": {\"content\": \"ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\", \"id\": \"72a56ee6-8054-462e-a419-30a688306418\" ...ì¤‘ëµ...}},\n",
    "                   {\"AIMessage\": {\"content\": \"ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\", \"id\": \"run-b71776ac-76e4-478e-adfd-cd70b5271f5a-0\" ...ì¤‘ëµ...}},\n",
    "                   {\"HumanMessage\": {\"content\": \"ë‚˜ëŠ” 30ì‚´ì´ê³  ì¸ê³µì§€ëŠ¥ì„ ê³µë¶€í•˜ê³ ìˆì–´.\", \"id\": \"c9c86e76-c1ec-4d6d-b1e4-0686fc4cfcee\" ...ì¤‘ëµ...}},\n",
    "                   {\"AIMessage\": {\"content\": \"ë©‹ì§€ë„¤ìš”! ì¸ê³µì§€ëŠ¥ì€ ì •ë§ í¥ë¯¸ë¡œìš´ ë¶„ì•¼ì£ . ì–´ë–¤ ë¶€ë¶„ì„ ê³µë¶€í•˜ê³  ê³„ì‹ ê°€ìš”? ...\", \"id\": \"run-bfd772b8-6b73-42ff-aeaf-14fae2b64f10-0\" ...ì¤‘ëµ...}},\n",
    "                   {\"HumanMessage\": {\"content\": \"ë‚˜ì— ëŒ€í•´ ì•„ëŠ”ê²Œìˆì–´?\", \"id\": \"11ca4ea2-2d73-4c9d-a469-fa7fe463ab7e\" ...ì¤‘ëµ...}},\n",
    "                   {\"AIMessage\": {\"content\": \"ë‹¹ì‹ ì— ëŒ€í•´ ì•Œê³  ìˆëŠ” ì •ë³´ëŠ” ëŒ€í™” ì¤‘ì— ê³µìœ í•´ ì£¼ì‹  ë‚´ìš©ë¿ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¹ì‹ ì˜ ì´ë¦„ì´ ì°½ìš°ì´ê³ , 30ì‚´ì´ë©°...\", \"id\": \"run-ce108968-6155-4316-9e04-1daeab7cb276-0\" ...ì¤‘ëµ...}}]},\n",
    "    \"next\": [],\n",
    "    \"config\": {\n",
    "      \"configurable\": {\n",
    "        \"thread_id\": \"initial_chat\",\n",
    "        \"checkpoint_ns\": \"\",\n",
    "        \"checkpoint_id\": \"1efcf246-7089-6e04-8007-da621da0c2cb\"\n",
    "      }\n",
    "    },\n",
    "    \"parent_config\": {\n",
    "      \"configurable\": {\n",
    "        \"thread_id\": \"initial_chat\",\n",
    "        \"checkpoint_ns\": \"\",\n",
    "        \"checkpoint_id\": \"1efcf246-5ede-638b-8006-e76f1cfe3378\"\n",
    "      }\n",
    "    },\n",
    "    \"metadata\": {.. ì¤‘ëµ ..}\n",
    "    \"created_at\": \"2025-01-10T07:27:52.616487+00:00\",\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. ê¸°ë³¸ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trace_function(enable_print=True, only_func_name=True)\n",
    "def node_answer(state:MessagesState)->MessagesState:\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"node_answer\", node_answer)\n",
    "builder.add_edge(START, \"node_answer\")\n",
    "builder.add_edge(\"node_answer\", END)\n",
    "ShortTermMemory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=ShortTermMemory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"initial_chat\", \n",
    "                           \"user_id\": \"changwoo\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "ğŸš€ Passing Through [node_answer] ..\u001b[0m\n",
      "\u001b[92m\n",
      "ğŸš€ Passing Through [node_answer] ..\u001b[0m\n",
      "\u001b[92m\n",
      "ğŸš€ Passing Through [node_answer] ..\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´', additional_kwargs={}, response_metadata={}, id='4a64b2bc-80e8-4caf-adce-1d6c44ea18f1'),\n",
       "  AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 14, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-57b9ff07-becd-4826-bf67-36ae98eae2c4-0', usage_metadata={'input_tokens': 14, 'output_tokens': 21, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚˜ëŠ” 30ì‚´ì´ê³  ì¸ê³µì§€ëŠ¥ì„ ê³µë¶€í•˜ê³ ìˆì–´.', additional_kwargs={}, response_metadata={}, id='6f4bc3bb-0004-4389-a703-c41bae4463c2'),\n",
       "  AIMessage(content='ë©‹ì§€ë„¤ìš”, ì°½ìš°ë‹˜! ì¸ê³µì§€ëŠ¥ì€ ì •ë§ í¥ë¯¸ë¡­ê³  ë¹ ë¥´ê²Œ ë°œì „í•˜ëŠ” ë¶„ì•¼ì£ . ì–´ë–¤ ë¶€ë¶„ì„ ê³µë¶€í•˜ê³  ê³„ì‹ ê°€ìš”? ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ìì—°ì–´ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì´ ìˆëŠ”ë°, íŠ¹ë³„íˆ ê´€ì‹¬ ìˆëŠ” ë¶„ì•¼ê°€ ìˆë‚˜ìš”? ê³µë¶€í•˜ë©´ì„œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 56, 'total_tokens': 140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-4cf71f03-fec2-473d-a350-8781b37bf722-0', usage_metadata={'input_tokens': 56, 'output_tokens': 84, 'total_tokens': 140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚˜ì— ëŒ€í•´ ì•„ëŠ”ê²Œìˆì–´?', additional_kwargs={}, response_metadata={}, id='63f1613b-20ec-4d79-ae5c-f721eee4799a'),\n",
       "  AIMessage(content='ì œê°€ ì°½ìš°ë‹˜ì— ëŒ€í•´ ì•Œê³  ìˆëŠ” ì •ë³´ëŠ” ì§€ê¸ˆê¹Œì§€ ëŒ€í™”ì—ì„œ ì œê³µí•´ì£¼ì‹  ë‚´ìš©ë¿ì…ë‹ˆë‹¤. ì°½ìš°ë‹˜ì€ 30ì‚´ì´ê³  ì¸ê³µì§€ëŠ¥ì„ ê³µë¶€í•˜ê³  ìˆë‹¤ëŠ” ì ì„ ë§ì”€í•´ì£¼ì…¨ì£ . ë” ì•Œê³  ì‹¶ì€ ê²ƒì´ë‚˜ ê³µìœ í•˜ê³  ì‹¶ì€ ê²ƒì´ ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 156, 'total_tokens': 221, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-9f6e7b16-a94d-456a-b1da-2d221d84c8bc-0', usage_metadata={'input_tokens': 156, 'output_tokens': 65, 'total_tokens': 221, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\"}, config)\n",
    "graph.invoke({\"messages\":\"ë‚˜ëŠ” 30ì‚´ì´ê³  ì¸ê³µì§€ëŠ¥ì„ ê³µë¶€í•˜ê³ ìˆì–´.\"}, config)\n",
    "graph.invoke({\"messages\":\"ë‚˜ì— ëŒ€í•´ ì•„ëŠ”ê²Œìˆì–´?\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(nodes={'__start__': Node(id='__start__', name='__start__', data=<class 'langchain_core.utils.pydantic.LangGraphInput'>, metadata=None), 'node_answer': Node(id='node_answer', name='node_answer', data=node_answer(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), metadata=None), '__end__': Node(id='__end__', name='__end__', data=<class 'langchain_core.utils.pydantic.LangGraphOutput'>, metadata=None)}, edges=[Edge(source='__start__', target='node_answer', data=None, conditional=False), Edge(source='node_answer', target='__end__', data=None, conditional=False)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_graph(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´', additional_kwargs={}, response_metadata={}, id='4a64b2bc-80e8-4caf-adce-1d6c44ea18f1'),\n",
       " AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 14, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-57b9ff07-becd-4826-bf67-36ae98eae2c4-0', usage_metadata={'input_tokens': 14, 'output_tokens': 21, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='ë‚˜ëŠ” 30ì‚´ì´ê³  ì¸ê³µì§€ëŠ¥ì„ ê³µë¶€í•˜ê³ ìˆì–´.', additional_kwargs={}, response_metadata={}, id='6f4bc3bb-0004-4389-a703-c41bae4463c2'),\n",
       " AIMessage(content='ë©‹ì§€ë„¤ìš”, ì°½ìš°ë‹˜! ì¸ê³µì§€ëŠ¥ì€ ì •ë§ í¥ë¯¸ë¡­ê³  ë¹ ë¥´ê²Œ ë°œì „í•˜ëŠ” ë¶„ì•¼ì£ . ì–´ë–¤ ë¶€ë¶„ì„ ê³µë¶€í•˜ê³  ê³„ì‹ ê°€ìš”? ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ìì—°ì–´ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì´ ìˆëŠ”ë°, íŠ¹ë³„íˆ ê´€ì‹¬ ìˆëŠ” ë¶„ì•¼ê°€ ìˆë‚˜ìš”? ê³µë¶€í•˜ë©´ì„œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 56, 'total_tokens': 140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-4cf71f03-fec2-473d-a350-8781b37bf722-0', usage_metadata={'input_tokens': 56, 'output_tokens': 84, 'total_tokens': 140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='ë‚˜ì— ëŒ€í•´ ì•„ëŠ”ê²Œìˆì–´?', additional_kwargs={}, response_metadata={}, id='63f1613b-20ec-4d79-ae5c-f721eee4799a'),\n",
       " AIMessage(content='ì œê°€ ì°½ìš°ë‹˜ì— ëŒ€í•´ ì•Œê³  ìˆëŠ” ì •ë³´ëŠ” ì§€ê¸ˆê¹Œì§€ ëŒ€í™”ì—ì„œ ì œê³µí•´ì£¼ì‹  ë‚´ìš©ë¿ì…ë‹ˆë‹¤. ì°½ìš°ë‹˜ì€ 30ì‚´ì´ê³  ì¸ê³µì§€ëŠ¥ì„ ê³µë¶€í•˜ê³  ìˆë‹¤ëŠ” ì ì„ ë§ì”€í•´ì£¼ì…¨ì£ . ë” ì•Œê³  ì‹¶ì€ ê²ƒì´ë‚˜ ê³µìœ í•˜ê³  ì‹¶ì€ ê²ƒì´ ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 156, 'total_tokens': 221, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-9f6e7b16-a94d-456a-b1da-2d221d84c8bc-0', usage_metadata={'input_tokens': 156, 'output_tokens': 65, 'total_tokens': 221, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.values['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93msnapshot(ìƒíƒœ,state) ë§ˆë‹¤ configì˜ checkpointê°€ ë‹¤ë¦…ë‹ˆë‹¤. í˜„ì¬ snapshotì˜ config : {'configurable': {'thread_id': 'initial_chat', 'checkpoint_ns': '', 'checkpoint_id': '1efcf28d-7779-6fd9-8007-883266b3d710'}}\u001b[0m\n",
      "\n",
      "ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "ë‚˜ëŠ” 30ì‚´ì´ê³  ì¸ê³µì§€ëŠ¥ì„ ê³µë¶€í•˜ê³ ìˆì–´.\n",
      "ë©‹ì§€ë„¤ìš”, ì°½ìš°ë‹˜! ì¸ê³µì§€ëŠ¥ì€ ì •ë§ í¥ë¯¸ë¡­ê³  ë¹ ë¥´ê²Œ ë°œì „í•˜ëŠ” ë¶„ì•¼ì£ . ì–´ë–¤ ë¶€ë¶„ì„ ê³µë¶€í•˜ê³  ê³„ì‹ ê°€ìš”? ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ìì—°ì–´ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì´ ìˆëŠ”ë°, íŠ¹ë³„íˆ ê´€ì‹¬ ìˆëŠ” ë¶„ì•¼ê°€ ìˆë‚˜ìš”? ê³µë¶€í•˜ë©´ì„œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "ë‚˜ì— ëŒ€í•´ ì•„ëŠ”ê²Œìˆì–´?\n",
      "ì œê°€ ì°½ìš°ë‹˜ì— ëŒ€í•´ ì•Œê³  ìˆëŠ” ì •ë³´ëŠ” ì§€ê¸ˆê¹Œì§€ ëŒ€í™”ì—ì„œ ì œê³µí•´ì£¼ì‹  ë‚´ìš©ë¿ì…ë‹ˆë‹¤. ì°½ìš°ë‹˜ì€ 30ì‚´ì´ê³  ì¸ê³µì§€ëŠ¥ì„ ê³µë¶€í•˜ê³  ìˆë‹¤ëŠ” ì ì„ ë§ì”€í•´ì£¼ì…¨ì£ . ë” ì•Œê³  ì‹¶ì€ ê²ƒì´ë‚˜ ê³µìœ í•˜ê³  ì‹¶ì€ ê²ƒì´ ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n",
      "\u001b[91m----------------------------------\u001b[0m\n",
      "\u001b[93msnapshot(ìƒíƒœ,state) ë§ˆë‹¤ configì˜ checkpointê°€ ë‹¤ë¦…ë‹ˆë‹¤. í˜„ì¬ snapshotì˜ config : {'configurable': {'thread_id': 'initial_chat', 'checkpoint_ns': '', 'checkpoint_id': '1efcf28d-6694-6008-8006-4c74c88c57ba'}}\u001b[0m\n",
      "\n",
      "ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "ë‚˜ëŠ” 30ì‚´ì´ê³  ì¸ê³µì§€ëŠ¥ì„ ê³µë¶€í•˜ê³ ìˆì–´.\n",
      "ë©‹ì§€ë„¤ìš”, ì°½ìš°ë‹˜! ì¸ê³µì§€ëŠ¥ì€ ì •ë§ í¥ë¯¸ë¡­ê³  ë¹ ë¥´ê²Œ ë°œì „í•˜ëŠ” ë¶„ì•¼ì£ . ì–´ë–¤ ë¶€ë¶„ì„ ê³µë¶€í•˜ê³  ê³„ì‹ ê°€ìš”? ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ìì—°ì–´ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì´ ìˆëŠ”ë°, íŠ¹ë³„íˆ ê´€ì‹¬ ìˆëŠ” ë¶„ì•¼ê°€ ìˆë‚˜ìš”? ê³µë¶€í•˜ë©´ì„œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "ë‚˜ì— ëŒ€í•´ ì•„ëŠ”ê²Œìˆì–´?\n",
      "\u001b[91m----------------------------------\u001b[0m\n",
      "\u001b[93msnapshot(ìƒíƒœ,state) ë§ˆë‹¤ configì˜ checkpointê°€ ë‹¤ë¦…ë‹ˆë‹¤. í˜„ì¬ snapshotì˜ config : {'configurable': {'thread_id': 'initial_chat', 'checkpoint_ns': '', 'checkpoint_id': '1efcf28d-6691-6a0f-8005-79cd36e39e42'}}\u001b[0m\n",
      "\n",
      "ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "ë‚˜ëŠ” 30ì‚´ì´ê³  ì¸ê³µì§€ëŠ¥ì„ ê³µë¶€í•˜ê³ ìˆì–´.\n",
      "ë©‹ì§€ë„¤ìš”, ì°½ìš°ë‹˜! ì¸ê³µì§€ëŠ¥ì€ ì •ë§ í¥ë¯¸ë¡­ê³  ë¹ ë¥´ê²Œ ë°œì „í•˜ëŠ” ë¶„ì•¼ì£ . ì–´ë–¤ ë¶€ë¶„ì„ ê³µë¶€í•˜ê³  ê³„ì‹ ê°€ìš”? ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ìì—°ì–´ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì´ ìˆëŠ”ë°, íŠ¹ë³„íˆ ê´€ì‹¬ ìˆëŠ” ë¶„ì•¼ê°€ ìˆë‚˜ìš”? ê³µë¶€í•˜ë©´ì„œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "\u001b[91m----------------------------------\u001b[0m\n",
      "\u001b[93msnapshot(ìƒíƒœ,state) ë§ˆë‹¤ configì˜ checkpointê°€ ë‹¤ë¦…ë‹ˆë‹¤. í˜„ì¬ snapshotì˜ config : {'configurable': {'thread_id': 'initial_chat', 'checkpoint_ns': '', 'checkpoint_id': '1efcf28d-668d-6afd-8004-61513804372b'}}\u001b[0m\n",
      "\n",
      "ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "ë‚˜ëŠ” 30ì‚´ì´ê³  ì¸ê³µì§€ëŠ¥ì„ ê³µë¶€í•˜ê³ ìˆì–´.\n",
      "ë©‹ì§€ë„¤ìš”, ì°½ìš°ë‹˜! ì¸ê³µì§€ëŠ¥ì€ ì •ë§ í¥ë¯¸ë¡­ê³  ë¹ ë¥´ê²Œ ë°œì „í•˜ëŠ” ë¶„ì•¼ì£ . ì–´ë–¤ ë¶€ë¶„ì„ ê³µë¶€í•˜ê³  ê³„ì‹ ê°€ìš”? ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, ìì—°ì–´ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ì˜ì—­ì´ ìˆëŠ”ë°, íŠ¹ë³„íˆ ê´€ì‹¬ ìˆëŠ” ë¶„ì•¼ê°€ ìˆë‚˜ìš”? ê³µë¶€í•˜ë©´ì„œ ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "\u001b[91m----------------------------------\u001b[0m\n",
      "\u001b[93msnapshot(ìƒíƒœ,state) ë§ˆë‹¤ configì˜ checkpointê°€ ë‹¤ë¦…ë‹ˆë‹¤. í˜„ì¬ snapshotì˜ config : {'configurable': {'thread_id': 'initial_chat', 'checkpoint_ns': '', 'checkpoint_id': '1efcf28d-5799-69c3-8003-9c9514956919'}}\u001b[0m\n",
      "\n",
      "ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "ë‚˜ëŠ” 30ì‚´ì´ê³  ì¸ê³µì§€ëŠ¥ì„ ê³µë¶€í•˜ê³ ìˆì–´.\n",
      "\u001b[91m----------------------------------\u001b[0m\n",
      "\u001b[93msnapshot(ìƒíƒœ,state) ë§ˆë‹¤ configì˜ checkpointê°€ ë‹¤ë¦…ë‹ˆë‹¤. í˜„ì¬ snapshotì˜ config : {'configurable': {'thread_id': 'initial_chat', 'checkpoint_ns': '', 'checkpoint_id': '1efcf28d-5797-6092-8002-0f86e8b66eae'}}\u001b[0m\n",
      "\n",
      "ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "\u001b[91m----------------------------------\u001b[0m\n",
      "\u001b[93msnapshot(ìƒíƒœ,state) ë§ˆë‹¤ configì˜ checkpointê°€ ë‹¤ë¦…ë‹ˆë‹¤. í˜„ì¬ snapshotì˜ config : {'configurable': {'thread_id': 'initial_chat', 'checkpoint_ns': '', 'checkpoint_id': '1efcf28d-5792-6a1b-8001-eb63bc582019'}}\u001b[0m\n",
      "\n",
      "ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n",
      "\u001b[91m----------------------------------\u001b[0m\n",
      "\u001b[93msnapshot(ìƒíƒœ,state) ë§ˆë‹¤ configì˜ checkpointê°€ ë‹¤ë¦…ë‹ˆë‹¤. í˜„ì¬ snapshotì˜ config : {'configurable': {'thread_id': 'initial_chat', 'checkpoint_ns': '', 'checkpoint_id': '1efcf28d-4faa-6866-8000-e2abc0212da2'}}\u001b[0m\n",
      "\n",
      "ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\n",
      "\u001b[91m----------------------------------\u001b[0m\n",
      "\u001b[93msnapshot(ìƒíƒœ,state) ë§ˆë‹¤ configì˜ checkpointê°€ ë‹¤ë¦…ë‹ˆë‹¤. í˜„ì¬ snapshotì˜ config : {'configurable': {'thread_id': 'initial_chat', 'checkpoint_ns': '', 'checkpoint_id': '1efcf28d-4fa6-6d6a-bfff-3e208aad5aff'}}\u001b[0m\n",
      "\n",
      "\u001b[91m----------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "state_history = graph.get_state_history(config)\n",
    "for snapshot in state_history:\n",
    "    print(f\"{YELLOW}snapshot(ìƒíƒœ,state) ë§ˆë‹¤ configì˜ checkpointê°€ ë‹¤ë¦…ë‹ˆë‹¤. í˜„ì¬ snapshotì˜ config : {snapshot.config}{RESET}\\n\")\n",
    "    for message in snapshot.values['messages']:\n",
    "        print(message.content)\n",
    "    print(f\"{RED}----------------------------------{RESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. replay í…ŒìŠ¤íŠ¸\n",
    "\n",
    "- ëŒ€í™” ê¸°ë¡ì¤‘ íŠ¹ì • snapshot ë¶€ë¶„ë§Œ ê°€ì ¸ì™€ì„œ, ê·¸ë˜í”„ë¥¼ ì¬ì‹¤í–‰í•¨.\n",
    "\n",
    "    - `ì…ë ¥ê°’ì€ ë™ì¼`í•˜ë‹¤.\n",
    "\n",
    "- ì¤‘ìš”í•œ ì ì€ `ì¬ì‹¤í–‰í•˜ë ¤ëŠ” ë¶€ë¶„ì˜ config`ë¥¼ ë„£ì–´ì¤˜ì•¼í•œë‹¤.\n",
    "\n",
    "- ì´ì „ ê¸°ë¡ì€ ì‚­ì œë¨. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\n"
     ]
    }
   ],
   "source": [
    "state_history = [s for s in graph.get_state_history(config)]\n",
    "snapshot_to_replay_from_initial = state_history[-2] # ì œì¼ ì²« ì…ë ¥ê°’ì´ ë‚˜ì˜´.\n",
    "for message in snapshot_to_replay_from_initial.values['messages']:\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "ğŸš€ Passing Through [node_answer] ..\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´', additional_kwargs={}, response_metadata={}, id='4a64b2bc-80e8-4caf-adce-1d6c44ea18f1'),\n",
       "  AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 14, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-c69cecf7-77ab-4826-9cb3-770c40c1364b-0', usage_metadata={'input_tokens': 14, 'output_tokens': 21, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(None, snapshot_to_replay_from_initial.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "for message in snapshot.values['messages']:\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. forking í…ŒìŠ¤íŠ¸\n",
    "\n",
    "- forkingì€ `ì…ë ¥ê°’ì„ ë°”ê¾¸ì–´` ê·¸ë˜í”„ë¥¼ ì¬ì‹¤í–‰í•˜ëŠ”ê±¸ ì˜ë¯¸í•¨.\n",
    "\n",
    "- ì¤‘ìš”í•œ ì ì€ `ì…ë ¥ê°’ì„ ë°”ê¾¸ê³  ì¬ì‹¤í–‰í•˜ë ¤ëŠ” ë¶€ë¶„ì˜ config`ë¥¼ ë„£ì–´ì¤˜ì•¼í•œë‹¤.\n",
    "\n",
    "- ì´ì „ ê¸°ë¡ì€ ì‚­ì œë¨. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\n"
     ]
    }
   ],
   "source": [
    "state_history = [s for s in graph.get_state_history(config)]\n",
    "snapshot_to_replay_with_new_value = state_history[-2] # ì œì¼ ì²« ì…ë ¥ê°’ì´ ë‚˜ì˜´.\n",
    "for message in snapshot_to_replay_with_new_value.values['messages']:\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fork_config = graph.update_state(snapshot_to_replay_with_new_value.config, \n",
    "                                 {\"messages\": [HumanMessage(content=\"ì•ˆë…• ë‚˜ëŠ” í™ê¸¸ë™ì´ë¼ê³ í•´.\",\n",
    "                                                            id=snapshot_to_replay_with_new_value.values['messages'][0].id)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "ğŸš€ Passing Through [node_answer] ..\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='ì•ˆë…• ë‚˜ëŠ” í™ê¸¸ë™ì´ë¼ê³ í•´.', additional_kwargs={}, response_metadata={}, id='4a64b2bc-80e8-4caf-adce-1d6c44ea18f1'),\n",
       "  AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, í™ê¸¸ë™ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 16, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-18b1cd3e-7162-4983-b5a7-aae17d8e621c-0', usage_metadata={'input_tokens': 16, 'output_tokens': 22, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(None, fork_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
