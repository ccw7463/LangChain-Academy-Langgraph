{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Human Feedback 사용하기\n",
    "\n",
    "Interrupt 걸어서 Feedback 받는 방식 2가지 있음.\n",
    "\n",
    "1. compile 할때 `interrupt_before` 지정\n",
    "\n",
    "```python \n",
    "graph = builder.compile(interrupt_before=[\"tools\"],\n",
    "                        checkpointer=ShortTermMemory)\n",
    "```\n",
    "\n",
    "\n",
    "2. 노드 내부에서 `NodeInterrupt` 발생\n",
    "\n",
    "```python\n",
    "raise NodeInterrupt(f\"입력받은 문자열의 길이가 너무 깁니다. 최대 10자까지 입력해주세요.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.base import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 첫번째 방식 (interrupt_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trace_function(enable_print=True, only_func_name=True)\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "@trace_function(enable_print=True, only_func_name=True)\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@trace_function(enable_print=True, only_func_name=True)\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Adds a and b.\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "@trace_function(enable_print=True, only_func_name=True)\n",
    "def node_assistant(state: MessagesState):\n",
    "    system_message = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "    return {\"messages\": [llm_with_tools.invoke([system_message] + state[\"messages\"])]}\n",
    "    \n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"node_assistant\", node_assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"node_assistant\")\n",
    "builder.add_conditional_edges(\"node_assistant\",tools_condition)\n",
    "builder.add_edge(\"tools\", \"node_assistant\")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "breakpoint 간단 예제 - Tool Node 에 Breakpoint 설정\n",
    "\n",
    "- 함수들에도 `trace_function` 데코레이터를 붙였지만, 통과하지 않음.\n",
    "\n",
    "- state의 messages 값의 마지막도 tool call 요청문\n",
    "\n",
    "- Graph 이어서 실행시, 사용자에게 입력받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShortTermMemory = MemorySaver()\n",
    "graph_with_interrupt_tools = builder.compile(interrupt_before=[\"tools\"], # tools 노드 전에 멈춤\n",
    "                                             checkpointer=ShortTermMemory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "🚀 Passing Through [node_assistant] ..\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='fa74446b-ff81-4116-87c3-d49d28e6b98e'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mkVdFzg22CeMhet3fXo6Stoq', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 143, 'total_tokens': 161, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-905af210-3c09-4411-a588-1001e5ed6b96-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_mkVdFzg22CeMhet3fXo6Stoq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 143, 'output_tokens': 18, 'total_tokens': 161, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_with_interrupt_tools.invoke({\"messages\": \"Multiply 2 and 3\"}, config)\n",
    "graph_with_interrupt_tools.get_state(config).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "🚀 Passing Through [multiply] ..\u001b[0m\n",
      "\u001b[92m\n",
      "🚀 Passing Through [node_assistant] ..\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "user_approval = input(\"Do you want to call the tool? (yes/no): \")\n",
    "if user_approval.lower() == \"yes\":\n",
    "    graph_with_interrupt_tools.invoke(None, config) # yes 일 경우 tool 노드 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='fa74446b-ff81-4116-87c3-d49d28e6b98e'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mkVdFzg22CeMhet3fXo6Stoq', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 143, 'total_tokens': 161, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-905af210-3c09-4411-a588-1001e5ed6b96-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_mkVdFzg22CeMhet3fXo6Stoq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 143, 'output_tokens': 18, 'total_tokens': 161, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='6', name='multiply', id='01179235-0f48-4ba9-b8c7-582a4f473a0c', tool_call_id='call_mkVdFzg22CeMhet3fXo6Stoq'),\n",
       "  AIMessage(content='The result of multiplying 2 and 3 is 6.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 168, 'total_tokens': 183, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-2ad84f55-204f-4c49-a75e-ac86feb245fe-0', usage_metadata={'input_tokens': 168, 'output_tokens': 15, 'total_tokens': 183, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_with_interrupt_tools.get_state(config).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humanfeedback 간단 예제 - Assistant Node 에 Breakpoint 설정\n",
    "\n",
    "- state의 messages 값의 마지막이 사용자 요청문\n",
    "\n",
    "- `update_state`를 통해 사용자 요청문 재입력 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShortTermMemory = MemorySaver()\n",
    "graph_with_interrupt_assitant = builder.compile(interrupt_before=[\"node_assistant\"], # node_assistant 노드 전에 멈춤\n",
    "                                                checkpointer=ShortTermMemory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='2 곱하기 3은?', additional_kwargs={}, response_metadata={}, id='f0afa064-a46b-419e-853d-5a67c14712d0')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_with_interrupt_assitant.invoke({\"messages\": \"2 곱하기 3은?\"}, config)\n",
    "graph_with_interrupt_assitant.get_state(config).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "🚀 Passing Through [node_assistant] ..\u001b[0m\n",
      "\u001b[92m\n",
      "🚀 Passing Through [multiply] ..\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='2 곱하기 3은?', additional_kwargs={}, response_metadata={}, id='f0afa064-a46b-419e-853d-5a67c14712d0'),\n",
       "  HumanMessage(content='아! 잘못말헀다. 3 곱하기 3은?', additional_kwargs={}, response_metadata={}, id='d11d7b3a-8602-459a-b239-f504022ac91c'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9kAgyb18v2jZb8ygXe3NCW9A', 'function': {'arguments': '{\"a\":3,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 167, 'total_tokens': 185, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6c5d90bf-ddba-46d0-8992-be72d6a37170-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 3}, 'id': 'call_9kAgyb18v2jZb8ygXe3NCW9A', 'type': 'tool_call'}], usage_metadata={'input_tokens': 167, 'output_tokens': 18, 'total_tokens': 185, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  ToolMessage(content='9', name='multiply', id='433b7e2a-a1ec-4b92-9ad6-8ae9dbecd5fe', tool_call_id='call_9kAgyb18v2jZb8ygXe3NCW9A')]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_with_interrupt_assitant.update_state(config,\n",
    "                                           {\"messages\": [HumanMessage(content=\"아! 잘못말헀다. 3 곱하기 3은?\")]})\n",
    "graph_with_interrupt_assitant.invoke(None, config) # 실제로 3 x 3 계산 수행\n",
    "graph_with_interrupt_assitant.get_state(config).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Node 내부에서 NodeInterrupt 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.errors import NodeInterrupt\n",
    "\n",
    "@trace_function(enable_print=True, only_func_name=True)\n",
    "def step_1(state:MessagesState) -> MessagesState:\n",
    "    return state\n",
    "\n",
    "@trace_function(enable_print=True, only_func_name=True)\n",
    "def step_2(state:MessagesState) -> MessagesState:\n",
    "    if len(state['messages'][-1].content) > 5:\n",
    "        print(f\"Received input that is longer than 5 characters: {state['messages'][-1].content}\")\n",
    "        raise NodeInterrupt(f\"Received input that is longer than 5 characters: {state['messages'][-1].content}\")\n",
    "    return state\n",
    "\n",
    "@trace_function(enable_print=True, only_func_name=True)\n",
    "def step_3(state:MessagesState) -> MessagesState:\n",
    "    return state\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"step_1\", step_1)\n",
    "builder.add_node(\"step_2\", step_2)\n",
    "builder.add_node(\"step_3\", step_3)\n",
    "builder.add_edge(START, \"step_1\")\n",
    "builder.add_edge(\"step_1\", \"step_2\")\n",
    "builder.add_edge(\"step_2\", \"step_3\")\n",
    "builder.add_edge(\"step_3\", END)\n",
    "memory = MemorySaver()\n",
    "graph_with_node_interrupt = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "🚀 Passing Through [step_1] ..\u001b[0m\n",
      "\u001b[92m\n",
      "🚀 Passing Through [step_2] ..\u001b[0m\n",
      "Received input that is longer than 5 characters: 안녕하세요, 저는 창우라고 합니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='안녕하세요, 저는 창우라고 합니다.', additional_kwargs={}, response_metadata={}, id='3b81c80f-082b-4fff-9c1d-f6a3c6ed782d')]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_with_node_interrupt.invoke({\"messages\": \"안녕하세요, 저는 창우라고 합니다.\"}, config)\n",
    "graph_with_node_interrupt.get_state(config).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\n",
      "🚀 Passing Through [step_2] ..\u001b[0m\n",
      "\u001b[92m\n",
      "🚀 Passing Through [step_3] ..\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='안녕하세요, 저는 창우라고 합니다.', additional_kwargs={}, response_metadata={}, id='3b81c80f-082b-4fff-9c1d-f6a3c6ed782d'),\n",
       "  HumanMessage(content='안녕', additional_kwargs={}, response_metadata={}, id='03c51dd0-7d02-4b29-b6f2-6063d573870c')]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_with_node_interrupt.update_state(config, {\"messages\": [HumanMessage(content=\"안녕\")]})\n",
    "graph_with_node_interrupt.invoke(None, config)\n",
    "graph_with_node_interrupt.get_state(config).values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
