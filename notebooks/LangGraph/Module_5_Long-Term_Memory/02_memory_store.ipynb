{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "load_dotenv()\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고) https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.SearchOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LongTermMemory = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMESPACE = (\"memories\", \"changwoo\") \n",
    "\n",
    "key = \"personal_info\"\n",
    "value = {\"age\" : \"29\", \n",
    "         \"major\": \"Computer Engineering\",\n",
    "         \"hobby\": \"working out\",\n",
    "         \"favorite_food\": \"pork\"}\n",
    "\n",
    "LongTermMemory.put(NAMESPACE,  # directory, user name\n",
    "                   key,  # sub_directory\n",
    "                   value) # values\n",
    "\n",
    "key = \"Education_level\"\n",
    "value = {\"Bachelor's degree\" : \"Electrical Engineering\", \n",
    "         \"Master's degree\": \"Computer Engineering\",\n",
    "         \"Doctoral degree\": \"Computer Engineering\"}\n",
    "\n",
    "LongTermMemory.put(NAMESPACE,  # directory, user name\n",
    "                   key,  # sub_directory\n",
    "                   value) # values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== NAMESPACE 영역 데이터 ====\n",
      "{'value': {'age': '29', 'major': 'Computer Engineering', 'hobby': 'working out', 'favorite_food': 'pork'}, 'key': 'personal_info', 'namespace': ['memories', 'changwoo'], 'created_at': '2024-11-27T08:36:29.961334+00:00', 'updated_at': '2024-11-27T08:36:29.961335+00:00'}\n",
      "{'value': {\"Bachelor's degree\": 'Electrical Engineering', \"Master's degree\": 'Computer Engineering', 'Doctoral degree': 'Computer Engineering'}, 'key': 'Education_level', 'namespace': ['memories', 'changwoo'], 'created_at': '2024-11-27T08:36:29.961397+00:00', 'updated_at': '2024-11-27T08:36:29.961398+00:00'}\n",
      "\n",
      "==== NAMESPACE 영역 personal_info 데이터 ====\n",
      "{'value': {'age': '29', 'major': 'Computer Engineering', 'hobby': 'working out', 'favorite_food': 'pork'}, 'key': 'personal_info', 'namespace': ['memories', 'changwoo'], 'created_at': '2024-11-27T08:36:29.961334+00:00', 'updated_at': '2024-11-27T08:36:29.961335+00:00'}\n",
      "\n",
      "==== NAMESPACE 영역 Education_level 데이터 ====\n",
      "{'value': {\"Bachelor's degree\": 'Electrical Engineering', \"Master's degree\": 'Computer Engineering', 'Doctoral degree': 'Computer Engineering'}, 'key': 'Education_level', 'namespace': ['memories', 'changwoo'], 'created_at': '2024-11-27T08:36:29.961397+00:00', 'updated_at': '2024-11-27T08:36:29.961398+00:00'}\n"
     ]
    }
   ],
   "source": [
    "# search with namespace (search)\n",
    "memories = LongTermMemory.search(NAMESPACE)\n",
    "print(\"==== NAMESPACE 영역 데이터 ====\")\n",
    "for memory in memories:\n",
    "    print(memory.dict())\n",
    "\n",
    "\n",
    "# search with namespace and key (get)\n",
    "print(\"\\n==== NAMESPACE 영역 personal_info 데이터 ====\")\n",
    "memory = LongTermMemory.get(NAMESPACE,\"personal_info\")\n",
    "print(memory.dict())\n",
    "\n",
    "print(\"\\n==== NAMESPACE 영역 Education_level 데이터 ====\")\n",
    "memory = LongTermMemory.get(NAMESPACE,\"Education_level\")\n",
    "print(memory.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Tensor' from 'torch' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Tensor' from 'torch' (unknown location)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/langchain-study-repo-jLHV_RkI-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Tensor' from 'torch' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# LLM = ChatOpenAI(model=\"gpt-4o\", \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#                  temperature=0) \u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLM\n",
      "File \u001b[0;32m/workspace/changwoo/Langchain/models/model.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_huggingface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatHuggingFace\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, SystemMessage, AIMessage\n\u001b[0;32m----> 8\u001b[0m LLM \u001b[38;5;241m=\u001b[39m \u001b[43mChatHuggingFace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHuggingFaceEndpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mURLConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL_URL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhuggingfacehub_api_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHFConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHF_API_TOKEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModelConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMAX_NEW_TOKENS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModelConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTOP_K\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModelConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTOP_P\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModelConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTEMPERATURE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModelConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREPETATION_PENALTY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreaming\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<|im_end|>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUsedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/langchain-study-repo-jLHV_RkI-py3.10/lib/python3.10/site-packages/langchain_huggingface/chat_models/huggingface.py:319\u001b[0m, in \u001b[0;36mChatHuggingFace.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_model_id()\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    324\u001b[0m         AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id)\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/langchain-study-repo-jLHV_RkI-py3.10/lib/python3.10/site-packages/transformers/__init__.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     29\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     logging,\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/langchain-study-repo-jLHV_RkI-py3.10/lib/python3.10/site-packages/transformers/dependency_versions_check.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[1;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m ]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/langchain-study-repo-jLHV_RkI-py3.10/lib/python3.10/site-packages/transformers/utils/__init__.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbone_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackboneConfigMixin, BackboneMixin\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_template_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocstringParsingException, TypeHintParsingException, get_json_schema\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     add_code_sample_docstrings,\n\u001b[1;32m     31\u001b[0m     add_end_docstrings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     replace_return_docstrings,\n\u001b[1;32m     36\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/langchain-study-repo-jLHV_RkI-py3.10/lib/python3.10/site-packages/transformers/utils/chat_template_utils.py:39\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m     42\u001b[0m BASIC_TYPES \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, Any, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Extracts the initial segment of the docstring, containing the function description\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Tensor' from 'torch' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "# LLM = ChatOpenAI(model=\"gpt-4o\", \n",
    "#                  temperature=0) \n",
    "\n",
    "from models.model import LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE_PROMPT = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# Create new memory from the chat history and any existing memory\n",
    "CREATE_MEMORY_PROMPT = \"\"\"\"You are collecting information about the user to personalize your responses.\n",
    "\n",
    "CURRENT USER INFORMATION:\n",
    "{memory}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Review the chat history below carefully\n",
    "2. Identify new information about the user, such as:\n",
    "   - Personal details (name, location)\n",
    "   - Preferences (likes, dislikes)\n",
    "   - Interests and hobbies\n",
    "   - Past experiences\n",
    "   - Goals or future plans\n",
    "3. Merge any new information with existing memory\n",
    "4. Format the memory as a clear, bulleted list\n",
    "5. If new information conflicts with existing memory, keep the most recent version\n",
    "\n",
    "Remember: Only include factual information directly stated by the user. Do not make assumptions or inferences.\n",
    "\n",
    "Based on the chat history below, please update the user information:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory(namespace, \n",
    "               key,\n",
    "               store:BaseStore):\n",
    "    \"\"\"\n",
    "        Des:\n",
    "            Get memory\n",
    "    \"\"\"\n",
    "    # Get memory from user id\n",
    "    existing_memory = store.get(namespace=namespace,\n",
    "                                key=key)\n",
    "\n",
    "    # Extract the actual memory content if it exists and add a prefix\n",
    "    if existing_memory:\n",
    "        existing_memory_content = existing_memory.value.get('memory')\n",
    "    else:\n",
    "        existing_memory_content = \"No existing memory found.\"\n",
    "    return existing_memory_content\n",
    "\n",
    "def Node_get_response(state: MessagesState, \n",
    "                      config: RunnableConfig, \n",
    "                      store: BaseStore):\n",
    "    \"\"\"\n",
    "        Des:\n",
    "            Load memory from the store and use it to personalize the chatbot's response.\n",
    "    \"\"\"\n",
    "    NAMESPACE = (\"memories\", config[\"configurable\"][\"user_id\"])\n",
    "    key = \"chat_user_memory\"\n",
    "    existing_memory_content = get_memory(NAMESPACE, \n",
    "                                         key, \n",
    "                                         store)\n",
    "    SYSTEM_MESSAGE = MODEL_SYSTEM_MESSAGE_PROMPT.format(memory=existing_memory_content)\n",
    "    INPUT = [SystemMessage(content=SYSTEM_MESSAGE)]+state[\"messages\"]\n",
    "    OUTPUT = LLM.invoke(INPUT)\n",
    "    return {\"messages\":OUTPUT}\n",
    "\n",
    "def Node_write_memory(state: MessagesState, \n",
    "                      config: RunnableConfig, \n",
    "                      store: BaseStore):\n",
    "    \"\"\"\n",
    "        Des:\n",
    "            Reflect on the chat history and save a memory to the store.\n",
    "    \"\"\"\n",
    "    NAMESPACE = (\"memories\", config[\"configurable\"][\"user_id\"])\n",
    "    key = \"chat_user_memory\"\n",
    "    existing_memory_content = get_memory(NAMESPACE, \n",
    "                                         key, \n",
    "                                         store)\n",
    "    SYSTEM_MESSAGE = CREATE_MEMORY_PROMPT.format(memory=existing_memory_content)\n",
    "    INPUT = [SystemMessage(content=SYSTEM_MESSAGE)]+state[\"messages\"]\n",
    "    OUTPUT = LLM.invoke(INPUT)\n",
    "    store.put(NAMESPACE, \n",
    "              key, \n",
    "              {\"memory\": OUTPUT.content})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"Node_get_response\", Node_get_response)\n",
    "builder.add_node(\"Node_write_memory\", Node_write_memory)\n",
    "builder.add_edge(START, \"Node_get_response\")\n",
    "builder.add_edge(\"Node_get_response\", \"Node_write_memory\")\n",
    "builder.add_edge(\"Node_write_memory\", END)\n",
    "\n",
    "# Checkpointer : short-term (within-thread) memory\n",
    "ShortTermMemory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=ShortTermMemory, \n",
    "                        store=LongTermMemory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Chat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Short-Term (within-thread) memory\n",
    "- thread ID\n",
    "2. Long-Term (cross-thread) memory\n",
    "- user ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Configuration\n",
    "- Thread : initial_chat\n",
    "- User : changwoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"initial_chat\", \n",
    "                           \"user_id\": \"changwoo\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat (1) Tell my Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is changwoo\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Changwoo! It's nice to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"Hi, my name is changwoo\")]}, \n",
    "                          config, \n",
    "                          stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat (2) Tell my Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm Phd Student in Pusan National University\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great to hear, Changwoo! Pursuing a PhD is a significant achievement. What are you studying at Pusan National University?\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"I'm Phd Student in Pusan National University\")]}, \n",
    "                          config, \n",
    "                          stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat (3) Tell my major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I have been studyin Artificial Intelligence, especially in Large Language Model\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's fascinating, Changwoo! Large Language Models are a rapidly evolving area in AI with a lot of exciting developments. Are you working on any specific projects or research questions related to Large Language Models?\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "message = \"\"\"I have been studyin Artificial Intelligence, especially in Large Language Model\"\"\"\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=message)]}, \n",
    "                          config, \n",
    "                          stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Short-Term Memory (within-thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is changwoo\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Changwoo! It's nice to meet you. How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm Phd Student in Pusan National University\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great to hear, Changwoo! Pursuing a PhD is a significant achievement. What are you studying at Pusan National University?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I have been studyin Artificial Intelligence, especially in Large Language Model\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's fascinating, Changwoo! Large Language Models are a rapidly evolving area in AI with a lot of exciting developments. Are you working on any specific projects or research questions related to Large Language Models?\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"initial_chat\"}}\n",
    "state = graph.get_state(thread).values\n",
    "for m in state[\"messages\"]: \n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Long-Term Memory (cross-thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value': {'memory': \"**Updated User Information:**\\n- User's name is Changwoo.\\n- Changwoo is a PhD student at Pusan National University.\\n- Changwoo is studying Artificial Intelligence, with a focus on Large Language Models.\"},\n",
       " 'key': 'chat_user_memory',\n",
       " 'namespace': ['memories', 'changwoo'],\n",
       " 'created_at': '2024-11-27T06:27:33.957232+00:00',\n",
       " 'updated_at': '2024-11-27T06:27:49.952595+00:00'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAMESPACE = (\"memories\", \"changwoo\") \n",
    "key = \"chat_user_memory\" # personal_info, Education_level\n",
    "existing_memory = LongTermMemory.get(NAMESPACE, key)\n",
    "existing_memory.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Configuration\n",
    "- Thread : second_chat\n",
    "- User : changwoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"second_chat\", \n",
    "                           \"user_id\": \"changwoo\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat (1) Tell my age, family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm 29 years old. I have a family of 7. Recently, a cute niece was born.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for sharing more about yourself, Changwoo! It's wonderful to hear about your growing family and the arrival of your cute niece. If there's anything specific you'd like to discuss or need help with, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "message = \"\"\"I'm 29 years old. I have a family of 7. Recently, a cute niece was born.\"\"\"\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=message)]}, \n",
    "                          config, \n",
    "                          stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat (2) Tell my hobby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My hobby is working out at the gym. I have been doing it for 2 years.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great to hear, Changwoo! Working out at the gym is a fantastic way to stay healthy and relieve stress, especially with the demands of your PhD studies. Since you've been doing it for 2 years, you must have developed a solid routine by now. If you ever want to share more about your workout routine or need tips on anything related to fitness, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "message = \"\"\"My hobby is working out at the gym. I have been doing it for 2 years.\"\"\"\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=message)]}, \n",
    "                          config, \n",
    "                          stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Short-Term Memory (within-thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm 29 years old. I have a family of 7. Recently, a cute niece was born.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for sharing more about yourself, Changwoo! It's wonderful to hear about your growing family and the arrival of your cute niece. If there's anything specific you'd like to discuss or need help with, feel free to let me know!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My hobby is working out at the gym. I have been doing it for 2 years.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great to hear, Changwoo! Working out at the gym is a fantastic way to stay healthy and relieve stress, especially with the demands of your PhD studies. Since you've been doing it for 2 years, you must have developed a solid routine by now. If you ever want to share more about your workout routine or need tips on anything related to fitness, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"second_chat\"}}\n",
    "state = graph.get_state(thread).values\n",
    "for m in state[\"messages\"]: \n",
    "    m.pretty_print()\n",
    "    # print(m.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Long-Term Memory (cross-thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'value': {'memory': \"**Updated User Information:**\\n- User's name is Changwoo.\\n- Changwoo is a PhD student at Pusan National University.\\n- Changwoo is studying Artificial Intelligence, with a focus on Large Language Models.\\n- Changwoo is 29 years old.\\n- Changwoo has a family of 7 members.\\n- Changwoo recently had a niece born.\\n- Changwoo's hobby is working out at the gym, which he has been doing for 2 years.\"},\n",
       " 'key': 'chat_user_memory',\n",
       " 'namespace': ['memories', 'changwoo'],\n",
       " 'created_at': '2024-11-27T06:27:33.957232+00:00',\n",
       " 'updated_at': '2024-11-27T06:28:43.330066+00:00'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAMESPACE = (\"memories\", \"changwoo\")\n",
    "key = \"chat_user_memory\"\n",
    "existing_memory = LongTermMemory.get(NAMESPACE, key)\n",
    "existing_memory.dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
