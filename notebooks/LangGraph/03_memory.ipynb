{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.base import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. ë©”ëª¨ë¦¬ ì‚¬ìš©í•˜ê¸°\n",
    "- ë©”ëª¨ë¦¬ ì¢…ë¥˜ëŠ” 2ê°€ì§€\n",
    "\n",
    "- short term memory : ë™ì¼ thread ë‚´ì—ì„œ ë©”ëª¨ë¦¬ ê³µìœ     \n",
    "    - ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ : `from langgraph.checkpoint.memory import MemorySaver`\n",
    "    - build compile ì‹œ checkpointer ì¸ìë¡œ ì‚¬ìš©\n",
    "    \n",
    "- long term memory : ë™ì¼ ì‚¬ìš©ì ë‚´ì—ì„œ ë©”ëª¨ë¦¬ ê³µìœ \n",
    "    - ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ : `from langgraph.store.memory import InMemoryStore`\n",
    "    - êµ¬ì¡°ëŠ” [namespace(directory, userid) -> key -> value]\n",
    "    - build compile ì‹œ store ì¸ìë¡œ ì‚¬ìš©\n",
    "\n",
    "- ì°¸ê³ ë§í¬\n",
    "    - https://langchain-ai.github.io/langgraph/concepts/memory/#storing-memories\n",
    "    - https://blog.langchain.dev/semantic-search-for-langgraph-memory/ (Semantic Search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ShortTerm í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trace_function\n",
    "def node_answer(state:MessagesState)->MessagesState:\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"node_answer\", node_answer)\n",
    "builder.add_edge(START, \"node_answer\")\n",
    "builder.add_edge(\"node_answer\", END)\n",
    "graph = builder.compile(checkpointer=ShortTermMemory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"initial_chat\", \n",
    "                           \"user_id\": \"changwoo\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidUpdateError",
     "evalue": "Expected dict, got <function trace_function.<locals>.wrapper.<locals>.wrapper at 0x7f5f8c18d4e0>\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidUpdateError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/Langchain/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1927\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1926\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1927\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m/workspace/Langchain/.venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1647\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1641\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1647\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1654\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/Langchain/.venv/lib/python3.11/site-packages/langgraph/pregel/runner.py:104\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    102\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/workspace/Langchain/.venv/lib/python3.11/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, writer)\u001b[0m\n\u001b[1;32m     38\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/Langchain/.venv/lib/python3.11/site-packages/langgraph/utils/runnable.py:412\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/workspace/Langchain/.venv/lib/python3.11/site-packages/langgraph/utils/runnable.py:176\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m    175\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m--> 176\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    178\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m/workspace/Langchain/.venv/lib/python3.11/site-packages/langgraph/pregel/write.py:85\u001b[0m, in \u001b[0;36mChannelWrite._write\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Any, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     writes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     80\u001b[0m         ChannelWriteEntry(write\u001b[38;5;241m.\u001b[39mchannel, \u001b[38;5;28minput\u001b[39m, write\u001b[38;5;241m.\u001b[39mskip_none, write\u001b[38;5;241m.\u001b[39mmapper)\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(write, ChannelWriteEntry) \u001b[38;5;129;01mand\u001b[39;00m write\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m PASSTHROUGH\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m write\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m write \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrites\n\u001b[1;32m     84\u001b[0m     ]\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_at_least_one_of\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/workspace/Langchain/.venv/lib/python3.11/site-packages/langgraph/pregel/write.py:129\u001b[0m, in \u001b[0;36mChannelWrite.do_write\u001b[0;34m(config, writes, require_at_least_one_of)\u001b[0m\n\u001b[1;32m    127\u001b[0m entries \u001b[38;5;241m=\u001b[39m [write \u001b[38;5;28;01mfor\u001b[39;00m write \u001b[38;5;129;01min\u001b[39;00m writes \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(write, ChannelWriteEntry)]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# process entries into values\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentries\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    133\u001b[0m values \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    134\u001b[0m     (write\u001b[38;5;241m.\u001b[39mchannel, val)\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m val, write \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, entries)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m write\u001b[38;5;241m.\u001b[39mskip_none \u001b[38;5;129;01mor\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m ]\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# filter out SKIP_WRITE values\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/Langchain/.venv/lib/python3.11/site-packages/langgraph/pregel/write.py:130\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m entries \u001b[38;5;241m=\u001b[39m [write \u001b[38;5;28;01mfor\u001b[39;00m write \u001b[38;5;129;01min\u001b[39;00m writes \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(write, ChannelWriteEntry)]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# process entries into values\u001b[39;00m\n\u001b[1;32m    129\u001b[0m values \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 130\u001b[0m     \u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m write\u001b[38;5;241m.\u001b[39mmapper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m write\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m write \u001b[38;5;129;01min\u001b[39;00m entries\n\u001b[1;32m    132\u001b[0m ]\n\u001b[1;32m    133\u001b[0m values \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    134\u001b[0m     (write\u001b[38;5;241m.\u001b[39mchannel, val)\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m val, write \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, entries)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m write\u001b[38;5;241m.\u001b[39mskip_none \u001b[38;5;129;01mor\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m ]\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# filter out SKIP_WRITE values\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/Langchain/.venv/lib/python3.11/site-packages/langgraph/graph/state.py:649\u001b[0m, in \u001b[0;36mCompiledStateGraph.attach_node.<locals>._get_state_key\u001b[0;34m(input, key)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    645\u001b[0m     msg \u001b[38;5;241m=\u001b[39m create_error_message(\n\u001b[1;32m    646\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected dict, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    647\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mINVALID_GRAPH_NODE_RETURN_VALUE,\n\u001b[1;32m    648\u001b[0m     )\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(msg)\n",
      "\u001b[0;31mInvalidUpdateError\u001b[0m: Expected dict, got <function trace_function.<locals>.wrapper.<locals>.wrapper at 0x7f5f8c18d4e0>\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE"
     ]
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92mğŸš€ Passing Through [node_answer] ..\u001b[0m\n",
      "\n",
      "\u001b[91m#### [Input State]\u001b[0m\n",
      "  args: ({'messages': [HumanMessage(content='ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´', additional_kwargs={}, response_metadata={}, id='6be8b76d-5170-423e-a361-d1d31f0ebf8a'), AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 14, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None}, id='run-1d679df0-3bc0-470c-b48d-3010fb1c72ab-0', usage_metadata={'input_tokens': 14, 'output_tokens': 22, 'total_tokens': 36, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ?', additional_kwargs={}, response_metadata={}, id='da06a4d5-0b7c-4756-a339-491815859884')]},)\n",
      "  kwargs: {}\n",
      "\n",
      "\u001b[94m#### [Output State]\u001b[0m\n",
      "  result: {'messages': [AIMessage(content='ë‹¹ì‹ ì˜ ì´ë¦„ì€ ì°½ìš°ë¼ê³  í•˜ì…¨ìŠµë‹ˆë‹¤. ë§ë‚˜ìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 49, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None}, id='run-a1e524e6-b0bf-4d69-bd66-74571d9bfdb2-0', usage_metadata={'input_tokens': 49, 'output_tokens': 16, 'total_tokens': 65, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´', additional_kwargs={}, response_metadata={}, id='6be8b76d-5170-423e-a361-d1d31f0ebf8a'),\n",
       "  AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 14, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None}, id='run-1d679df0-3bc0-470c-b48d-3010fb1c72ab-0', usage_metadata={'input_tokens': 14, 'output_tokens': 22, 'total_tokens': 36, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ?', additional_kwargs={}, response_metadata={}, id='da06a4d5-0b7c-4756-a339-491815859884'),\n",
       "  AIMessage(content='ë‹¹ì‹ ì˜ ì´ë¦„ì€ ì°½ìš°ë¼ê³  í•˜ì…¨ìŠµë‹ˆë‹¤. ë§ë‚˜ìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 49, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None}, id='run-a1e524e6-b0bf-4d69-bd66-74571d9bfdb2-0', usage_metadata={'input_tokens': 49, 'output_tokens': 16, 'total_tokens': 65, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ?\"}, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LongTerm í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¨ìˆœ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ë‚˜ì´': '29', 'ì „ê³µ': 'Computer Engineering', 'ì·¨ë¯¸': 'working out', 'ì¢‹ì•„í•˜ëŠ” ìŒì‹': 'pork'}\n",
      "{'ë‚˜ì´': '29', 'ì „ê³µ': 'Computer Engineering', 'ì·¨ë¯¸': 'working out', 'ì¢‹ì•„í•˜ëŠ” ìŒì‹': 'pork'}\n"
     ]
    }
   ],
   "source": [
    "directory = \"memories\"\n",
    "userid = \"changwoo\"\n",
    "key = \"chat_user_memory\"\n",
    "value = {\"ë‚˜ì´\" : \"29\", \n",
    "         \"ì „ê³µ\": \"Computer Engineering\",\n",
    "         \"ì·¨ë¯¸\": \"working out\",\n",
    "         \"ì¢‹ì•„í•˜ëŠ” ìŒì‹\": \"pork\"}\n",
    "\n",
    "# ê°’ ë„£ê¸°\n",
    "LongTermMemory.put(namespace=(directory, userid),\n",
    "                   key=key,  \n",
    "                   value=value)\n",
    "\n",
    "# ê°’ ê°€ì ¸ì˜¤ê¸° (1) - search í•¨ìˆ˜ ì‚¬ìš© (ë¦¬í„´íƒ€ì… : list)\n",
    "memory = LongTermMemory.search((directory, userid))\n",
    "print(memory[0].dict()['value'])\n",
    "\n",
    "\n",
    "# ê°’ ê°€ì ¸ì˜¤ê¸° (2) - get í•¨ìˆ˜ ì‚¬ìš© (ë¦¬í„´íƒ€ì… : dict)\n",
    "memory = LongTermMemory.get((directory, userid),key)\n",
    "print(memory.dict()['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ë˜í”„ë¥¼ í™œìš©í•œ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_config = ConfigDict()\n",
    "prompt_config.answer_prompt = \"\"\"ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì •ë³´ë¥¼ ê¸°ì–µí•˜ê³ , ì´ë¥¼ í™œìš©í•´ ê°œì¸í™”ëœ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ìœ ìš©í•œ ì¡°ë ¥ìì…ë‹ˆë‹¤. \n",
    "ì‚¬ìš©ìì— ëŒ€í•œ ê¸°ì–µì´ ìˆë‹¤ë©´ ì´ë¥¼ ì‚¬ìš©í•´ ì‘ë‹µì„ ë§ì¶¤í™”í•˜ì„¸ìš”.\n",
    "ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ê¸°ì–µì…ë‹ˆë‹¤ (ë¹„ì–´ ìˆì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤): {memory}\"\"\"\n",
    "\n",
    "prompt_config.create_memory_prompt =\"\"\"ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì‘ë‹µì„ ê°œì¸í™”í•˜ê¸° ìœ„í•´ ì‚¬ìš©ìì— ëŒ€í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "í˜„ì¬ ì‚¬ìš©ì ì •ë³´:\n",
    "{memory}\n",
    "\n",
    "ì§€ì¹¨:\n",
    "1. ì•„ë˜ì˜ ì±„íŒ… ê¸°ë¡ì„ ì£¼ì˜ ê¹Šê²Œ ê²€í† í•˜ì„¸ìš”.\n",
    "2. ì‚¬ìš©ìì— ëŒ€í•œ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ì‹ë³„í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ë©´:\n",
    "   - ê°œì¸ ì •ë³´ (ì´ë¦„, ìœ„ì¹˜ ë“±)\n",
    "   - ì„ í˜¸ ì‚¬í•­ (ì¢‹ì•„í•˜ëŠ” ê²ƒ, ì‹«ì–´í•˜ëŠ” ê²ƒ ë“±)\n",
    "   - ê´€ì‹¬ì‚¬ì™€ ì·¨ë¯¸\n",
    "   - ê³¼ê±° ê²½í—˜\n",
    "   - ëª©í‘œë‚˜ ë¯¸ë˜ ê³„íš\n",
    "3. ìƒˆë¡œìš´ ì •ë³´ë¥¼ ê¸°ì¡´ ë©”ëª¨ë¦¬ì™€ ë³‘í•©í•˜ì„¸ìš”.\n",
    "4. ë©”ëª¨ë¦¬ëŠ” ëª…í™•í•œ ë¶ˆë¦¿ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n",
    "5. ìƒˆë¡œìš´ ì •ë³´ê°€ ê¸°ì¡´ ë©”ëª¨ë¦¬ì™€ ì¶©ëŒí•  ê²½ìš°, ê°€ì¥ ìµœê·¼ ì •ë³´ë¥¼ ìœ ì§€í•˜ì„¸ìš”.\n",
    "\n",
    "ê¸°ì–µí•˜ì„¸ìš”: ì‚¬ìš©ìê°€ ì§ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰í•œ ì‚¬ì‹¤ì ì¸ ì •ë³´ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. ì¶”ì¸¡ì´ë‚˜ ì¶”ë¡ ì„ í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "\n",
    "ì•„ë˜ì˜ ì±„íŒ… ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”:\"\"\"\n",
    "\n",
    "@trace_function(enable_print=False)\n",
    "def get_memory(namespace, \n",
    "               key,\n",
    "               store:BaseStore):\n",
    "    \"\"\"\n",
    "        Des:\n",
    "            í˜„ì¬ ì €ì¥ëœ ì‚¬ìš©ì ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    existing_memory = store.get(namespace=namespace,\n",
    "                                key=key)\n",
    "    return existing_memory.value.get('memory') if existing_memory else \"í˜„ì¬ ì €ì¥ëœ ì‚¬ìš©ì ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    \n",
    "\n",
    "@trace_function(enable_print=False)\n",
    "def Node_get_response(state: MessagesState, \n",
    "                      config: RunnableConfig, \n",
    "                      store: BaseStore):\n",
    "    \"\"\"\n",
    "        Des:\n",
    "            ë‹µë³€ ìƒì„± ë…¸ë“œ\n",
    "    \"\"\"\n",
    "    namespace = (\"memories\", config[\"configurable\"][\"user_id\"])\n",
    "    key = \"chat_user_memory\"\n",
    "    existing_memory_content = get_memory(namespace=namespace, \n",
    "                                         key=key, \n",
    "                                         store=store)\n",
    "    system_message = prompt_config.answer_prompt.format(memory=existing_memory_content)\n",
    "    prompt = [SystemMessage(content=system_message)]+state[\"messages\"]\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\":response}\n",
    "\n",
    "@trace_function(enable_print=False)\n",
    "def Node_write_memory(state: MessagesState, \n",
    "                      config: RunnableConfig, \n",
    "                      store: BaseStore):\n",
    "    \"\"\"\n",
    "        Des:\n",
    "            ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì¸ì‹í•˜ê³ , ê°œì¸ì •ë³´ë¡œ ì €ì¥í•˜ëŠ” ë…¸ë“œ\n",
    "    \"\"\"\n",
    "    namespace = (\"memories\", config[\"configurable\"][\"user_id\"])\n",
    "    key = \"chat_user_memory\"\n",
    "    existing_memory_content = get_memory(namespace=namespace, \n",
    "                                         key=key, \n",
    "                                         store=store)\n",
    "    system_message = prompt_config.create_memory_prompt.format(memory=existing_memory_content)\n",
    "    prompt = [SystemMessage(content=system_message)]+state[\"messages\"]\n",
    "    response = llm.invoke(prompt)\n",
    "    store.put(namespace=namespace, \n",
    "              key=key, \n",
    "              value={\"memory\":response.content})\n",
    "    \n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"Node_get_response\", Node_get_response)\n",
    "builder.add_node(\"Node_write_memory\", Node_write_memory)\n",
    "builder.add_edge(START, \"Node_get_response\")\n",
    "builder.add_edge(\"Node_get_response\", \"Node_write_memory\")\n",
    "builder.add_edge(\"Node_write_memory\", END)\n",
    "graph = builder.compile(checkpointer=ShortTermMemory,\n",
    "                        store=LongTermMemory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"second_chat\", \n",
    "                           \"user_id\": \"changwoo\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´', additional_kwargs={}, response_metadata={}, id='3d30f693-16a2-43d3-857a-df1af004a1a1'),\n",
       "  AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 86, 'total_tokens': 107, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-98aacc6e-f38e-4cdf-82d0-3d86993664e6-0', usage_metadata={'input_tokens': 86, 'output_tokens': 21, 'total_tokens': 107, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´\"}, \n",
    "             config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´', additional_kwargs={}, response_metadata={}, id='3d30f693-16a2-43d3-857a-df1af004a1a1'),\n",
       "  AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 86, 'total_tokens': 107, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-98aacc6e-f38e-4cdf-82d0-3d86993664e6-0', usage_metadata={'input_tokens': 86, 'output_tokens': 21, 'total_tokens': 107, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚˜ëŠ” ì˜¬í•´ 30ì‚´ì´ê³ , í˜„ì¬ ë¶€ì‚°ëŒ€í•™êµì—ì„œ ë°•ì‚¬ê³¼ì •ì„ í•˜ê³ ìˆì–´.', additional_kwargs={}, response_metadata={}, id='edb20c34-6204-4efa-89b5-b6ffeceeae3a'),\n",
       "  AIMessage(content='ì˜¤, ì°½ìš°ë‹˜! ë¶€ì‚°ëŒ€í•™êµì—ì„œ ë°•ì‚¬ê³¼ì •ì„ í•˜ê³  ê³„ì‹œêµ°ìš”. ì •ë§ ë©‹ì§€ì„¸ìš”! ì „ê³µ ë¶„ì•¼ê°€ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”? ë°•ì‚¬ê³¼ì •ì—ì„œ ì–´ë–¤ ì—°êµ¬ë¥¼ í•˜ê³  ìˆëŠ”ì§€ ê¶ê¸ˆí•˜ë„¤ìš”.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 134, 'total_tokens': 185, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None}, id='run-705987ad-6fe1-44d3-97b2-0ba0f9dc7898-0', usage_metadata={'input_tokens': 134, 'output_tokens': 51, 'total_tokens': 185, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"ë‚˜ëŠ” ì˜¬í•´ 30ì‚´ì´ê³ , í˜„ì¬ ë¶€ì‚°ëŒ€í•™êµì—ì„œ ë°•ì‚¬ê³¼ì •ì„ í•˜ê³ ìˆì–´.\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´', additional_kwargs={}, response_metadata={}, id='3d30f693-16a2-43d3-857a-df1af004a1a1'),\n",
       "  AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 86, 'total_tokens': 107, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-98aacc6e-f38e-4cdf-82d0-3d86993664e6-0', usage_metadata={'input_tokens': 86, 'output_tokens': 21, 'total_tokens': 107, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚˜ëŠ” ì˜¬í•´ 30ì‚´ì´ê³ , í˜„ì¬ ë¶€ì‚°ëŒ€í•™êµì—ì„œ ë°•ì‚¬ê³¼ì •ì„ í•˜ê³ ìˆì–´.', additional_kwargs={}, response_metadata={}, id='edb20c34-6204-4efa-89b5-b6ffeceeae3a'),\n",
       "  AIMessage(content='ì˜¤, ì°½ìš°ë‹˜! ë¶€ì‚°ëŒ€í•™êµì—ì„œ ë°•ì‚¬ê³¼ì •ì„ í•˜ê³  ê³„ì‹œêµ°ìš”. ì •ë§ ë©‹ì§€ì„¸ìš”! ì „ê³µ ë¶„ì•¼ê°€ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”? ë°•ì‚¬ê³¼ì •ì—ì„œ ì–´ë–¤ ì—°êµ¬ë¥¼ í•˜ê³  ìˆëŠ”ì§€ ê¶ê¸ˆí•˜ë„¤ìš”.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 134, 'total_tokens': 185, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None}, id='run-705987ad-6fe1-44d3-97b2-0ba0f9dc7898-0', usage_metadata={'input_tokens': 134, 'output_tokens': 51, 'total_tokens': 185, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚´ ì·¨ë¯¸ëŠ” í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™í•˜ëŠ”ê±°ê³ , ë¼ì§€ê³ ê¸°ë¥¼ ì œì¼ì¢‹ì•„í•´', additional_kwargs={}, response_metadata={}, id='912d0ad6-6b6a-47ba-8f71-0ca21ce7980d'),\n",
       "  AIMessage(content='í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ì‹œëŠ”êµ°ìš”! ê±´ê°•ì„ ì˜ ì±™ê¸°ì‹œëŠ” ê²ƒ ê°™ì•„ ì¢‹ë„¤ìš”. ê·¸ë¦¬ê³  ë¼ì§€ê³ ê¸°ë¥¼ ì¢‹ì•„í•˜ì‹ ë‹¤ê³  í•˜ì…¨ìœ¼ë‹ˆ, í˜¹ì‹œ ì‚¼ê²¹ì‚´ ê°™ì€ ìš”ë¦¬ë¥¼ ì¦ê¸°ì‹œë‚˜ìš”? ë§›ìˆëŠ” ìŒì‹ê³¼ ìš´ë™ì˜ ì¡°í•©ì´ë¼ë‹ˆ ë©‹ì§€ë„¤ìš”!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 239, 'total_tokens': 309, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-04d7f469-305a-4f23-8113-726b29e897a6-0', usage_metadata={'input_tokens': 239, 'output_tokens': 70, 'total_tokens': 309, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"ë‚´ ì·¨ë¯¸ëŠ” í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™í•˜ëŠ”ê±°ê³ , ë¼ì§€ê³ ê¸°ë¥¼ ì œì¼ì¢‹ì•„í•´\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´', additional_kwargs={}, response_metadata={}, id='3d30f693-16a2-43d3-857a-df1af004a1a1'),\n",
       "  AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 86, 'total_tokens': 107, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-98aacc6e-f38e-4cdf-82d0-3d86993664e6-0', usage_metadata={'input_tokens': 86, 'output_tokens': 21, 'total_tokens': 107, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚˜ëŠ” ì˜¬í•´ 30ì‚´ì´ê³ , í˜„ì¬ ë¶€ì‚°ëŒ€í•™êµì—ì„œ ë°•ì‚¬ê³¼ì •ì„ í•˜ê³ ìˆì–´.', additional_kwargs={}, response_metadata={}, id='edb20c34-6204-4efa-89b5-b6ffeceeae3a'),\n",
       "  AIMessage(content='ì˜¤, ì°½ìš°ë‹˜! ë¶€ì‚°ëŒ€í•™êµì—ì„œ ë°•ì‚¬ê³¼ì •ì„ í•˜ê³  ê³„ì‹œêµ°ìš”. ì •ë§ ë©‹ì§€ì„¸ìš”! ì „ê³µ ë¶„ì•¼ê°€ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”? ë°•ì‚¬ê³¼ì •ì—ì„œ ì–´ë–¤ ì—°êµ¬ë¥¼ í•˜ê³  ìˆëŠ”ì§€ ê¶ê¸ˆí•˜ë„¤ìš”.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 134, 'total_tokens': 185, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None}, id='run-705987ad-6fe1-44d3-97b2-0ba0f9dc7898-0', usage_metadata={'input_tokens': 134, 'output_tokens': 51, 'total_tokens': 185, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚´ ì·¨ë¯¸ëŠ” í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™í•˜ëŠ”ê±°ê³ , ë¼ì§€ê³ ê¸°ë¥¼ ì œì¼ì¢‹ì•„í•´', additional_kwargs={}, response_metadata={}, id='912d0ad6-6b6a-47ba-8f71-0ca21ce7980d'),\n",
       "  AIMessage(content='í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ì‹œëŠ”êµ°ìš”! ê±´ê°•ì„ ì˜ ì±™ê¸°ì‹œëŠ” ê²ƒ ê°™ì•„ ì¢‹ë„¤ìš”. ê·¸ë¦¬ê³  ë¼ì§€ê³ ê¸°ë¥¼ ì¢‹ì•„í•˜ì‹ ë‹¤ê³  í•˜ì…¨ìœ¼ë‹ˆ, í˜¹ì‹œ ì‚¼ê²¹ì‚´ ê°™ì€ ìš”ë¦¬ë¥¼ ì¦ê¸°ì‹œë‚˜ìš”? ë§›ìˆëŠ” ìŒì‹ê³¼ ìš´ë™ì˜ ì¡°í•©ì´ë¼ë‹ˆ ë©‹ì§€ë„¤ìš”!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 239, 'total_tokens': 309, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-04d7f469-305a-4f23-8113-726b29e897a6-0', usage_metadata={'input_tokens': 239, 'output_tokens': 70, 'total_tokens': 309, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚˜ì— ëŒ€í•´ì„œ ì•Œê³ ìˆëŠ”ê²Œ ìˆì–´?', additional_kwargs={}, response_metadata={}, id='d681c693-ad25-4d3f-8e31-1e57f0f3377c'),\n",
       "  AIMessage(content='ë¬¼ë¡ ì´ì£ , ì°½ìš°ë‹˜! ì°½ìš°ë‹˜ì€ 30ì‚´ì´ê³ , ë¶€ì‚°ëŒ€í•™êµì—ì„œ ë°•ì‚¬ê³¼ì •ì„ í•˜ê³  ê³„ì‹œë©°, ì·¨ë¯¸ëŠ” í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™í•˜ëŠ” ê²ƒì´ê³ , ë¼ì§€ê³ ê¸°ë¥¼ ì¢‹ì•„í•˜ì‹ ë‹¤ê³  í•˜ì…¨ìŠµë‹ˆë‹¤. í˜¹ì‹œ ë” ì¶”ê°€í•˜ê³  ì‹¶ì€ ì •ë³´ê°€ ìˆê±°ë‚˜ ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 335, 'total_tokens': 412, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-94192bdd-748d-4f0c-b49e-cc08a6c52aa5-0', usage_metadata={'input_tokens': 335, 'output_tokens': 77, 'total_tokens': 412, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"ë‚˜ì— ëŒ€í•´ì„œ ì•Œê³ ìˆëŠ”ê²Œ ìˆì–´?\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´', additional_kwargs={}, response_metadata={}, id='3d30f693-16a2-43d3-857a-df1af004a1a1'),\n",
       "  AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 86, 'total_tokens': 107, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-98aacc6e-f38e-4cdf-82d0-3d86993664e6-0', usage_metadata={'input_tokens': 86, 'output_tokens': 21, 'total_tokens': 107, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚˜ëŠ” ì˜¬í•´ 30ì‚´ì´ê³ , í˜„ì¬ ë¶€ì‚°ëŒ€í•™êµì—ì„œ ë°•ì‚¬ê³¼ì •ì„ í•˜ê³ ìˆì–´.', additional_kwargs={}, response_metadata={}, id='edb20c34-6204-4efa-89b5-b6ffeceeae3a'),\n",
       "  AIMessage(content='ì˜¤, ì°½ìš°ë‹˜! ë¶€ì‚°ëŒ€í•™êµì—ì„œ ë°•ì‚¬ê³¼ì •ì„ í•˜ê³  ê³„ì‹œêµ°ìš”. ì •ë§ ë©‹ì§€ì„¸ìš”! ì „ê³µ ë¶„ì•¼ê°€ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”? ë°•ì‚¬ê³¼ì •ì—ì„œ ì–´ë–¤ ì—°êµ¬ë¥¼ í•˜ê³  ìˆëŠ”ì§€ ê¶ê¸ˆí•˜ë„¤ìš”.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 134, 'total_tokens': 185, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None}, id='run-705987ad-6fe1-44d3-97b2-0ba0f9dc7898-0', usage_metadata={'input_tokens': 134, 'output_tokens': 51, 'total_tokens': 185, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚´ ì·¨ë¯¸ëŠ” í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™í•˜ëŠ”ê±°ê³ , ë¼ì§€ê³ ê¸°ë¥¼ ì œì¼ì¢‹ì•„í•´', additional_kwargs={}, response_metadata={}, id='912d0ad6-6b6a-47ba-8f71-0ca21ce7980d'),\n",
       "  AIMessage(content='í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ì‹œëŠ”êµ°ìš”! ê±´ê°•ì„ ì˜ ì±™ê¸°ì‹œëŠ” ê²ƒ ê°™ì•„ ì¢‹ë„¤ìš”. ê·¸ë¦¬ê³  ë¼ì§€ê³ ê¸°ë¥¼ ì¢‹ì•„í•˜ì‹ ë‹¤ê³  í•˜ì…¨ìœ¼ë‹ˆ, í˜¹ì‹œ ì‚¼ê²¹ì‚´ ê°™ì€ ìš”ë¦¬ë¥¼ ì¦ê¸°ì‹œë‚˜ìš”? ë§›ìˆëŠ” ìŒì‹ê³¼ ìš´ë™ì˜ ì¡°í•©ì´ë¼ë‹ˆ ë©‹ì§€ë„¤ìš”!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 239, 'total_tokens': 309, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-04d7f469-305a-4f23-8113-726b29e897a6-0', usage_metadata={'input_tokens': 239, 'output_tokens': 70, 'total_tokens': 309, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚˜ì— ëŒ€í•´ì„œ ì•Œê³ ìˆëŠ”ê²Œ ìˆì–´?', additional_kwargs={}, response_metadata={}, id='d681c693-ad25-4d3f-8e31-1e57f0f3377c'),\n",
       "  AIMessage(content='ë¬¼ë¡ ì´ì£ , ì°½ìš°ë‹˜! ì°½ìš°ë‹˜ì€ 30ì‚´ì´ê³ , ë¶€ì‚°ëŒ€í•™êµì—ì„œ ë°•ì‚¬ê³¼ì •ì„ í•˜ê³  ê³„ì‹œë©°, ì·¨ë¯¸ëŠ” í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™í•˜ëŠ” ê²ƒì´ê³ , ë¼ì§€ê³ ê¸°ë¥¼ ì¢‹ì•„í•˜ì‹ ë‹¤ê³  í•˜ì…¨ìŠµë‹ˆë‹¤. í˜¹ì‹œ ë” ì¶”ê°€í•˜ê³  ì‹¶ì€ ì •ë³´ê°€ ìˆê±°ë‚˜ ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 335, 'total_tokens': 412, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-94192bdd-748d-4f0c-b49e-cc08a6c52aa5-0', usage_metadata={'input_tokens': 335, 'output_tokens': 77, 'total_tokens': 412, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ì•„ë‹ˆì•¼. ì˜ëª»ë§í–ˆì–´. ë‚´ì´ë¦„ì€ ê¹€í˜¸ì›ì´ê³ , ë‚˜ì´ëŠ” 54ì‚´ì´ì•¼. í˜„ì¬ ìŠ¤ë§ˆíŠ¸ì— íˆ¬ì—  ëŒ€í‘œë¡œ ì¼í•˜ê³ ìˆì–´.', additional_kwargs={}, response_metadata={}, id='c5c28aad-1572-4926-a997-5193506ee5fb'),\n",
       "  AIMessage(content='ì•Œê² ìŠµë‹ˆë‹¤, í˜¸ì›ë‹˜! ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤. ìŠ¤ë§ˆíŠ¸ì— íˆ¬ì— ì˜ ëŒ€í‘œë¡œ ì¼í•˜ê³  ê³„ì‹œë‹¤ë‹ˆ ì¸ìƒì ì´ë„¤ìš”. í˜¹ì‹œ íšŒì‚¬ì—ì„œëŠ” ì–´ë–¤ ë¶„ì•¼ì— ì§‘ì¤‘í•˜ê³  ê³„ì‹ ê°€ìš”? ê¶ê¸ˆí•©ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 460, 'total_tokens': 511, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-033a60ae-7899-442b-8ea3-62f0aca2a18a-0', usage_metadata={'input_tokens': 460, 'output_tokens': 51, 'total_tokens': 511, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"ì•„ë‹ˆì•¼. ì˜ëª»ë§í–ˆì–´. ë‚´ì´ë¦„ì€ ê¹€í˜¸ì›ì´ê³ , ë‚˜ì´ëŠ” 54ì‚´ì´ì•¼. í˜„ì¬ ìŠ¤ë§ˆíŠ¸ì— íˆ¬ì—  ëŒ€í‘œë¡œ ì¼í•˜ê³ ìˆì–´.\"}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='ì•ˆë…• ë‚˜ëŠ” ì°½ìš°ë¼ê³ í•´', additional_kwargs={}, response_metadata={}, id='3d30f693-16a2-43d3-857a-df1af004a1a1'),\n",
       "  AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ì°½ìš°ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 86, 'total_tokens': 107, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-98aacc6e-f38e-4cdf-82d0-3d86993664e6-0', usage_metadata={'input_tokens': 86, 'output_tokens': 21, 'total_tokens': 107, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚˜ëŠ” ì˜¬í•´ 30ì‚´ì´ê³ , í˜„ì¬ ë¶€ì‚°ëŒ€í•™êµì—ì„œ ë°•ì‚¬ê³¼ì •ì„ í•˜ê³ ìˆì–´.', additional_kwargs={}, response_metadata={}, id='edb20c34-6204-4efa-89b5-b6ffeceeae3a'),\n",
       "  AIMessage(content='ì˜¤, ì°½ìš°ë‹˜! ë¶€ì‚°ëŒ€í•™êµì—ì„œ ë°•ì‚¬ê³¼ì •ì„ í•˜ê³  ê³„ì‹œêµ°ìš”. ì •ë§ ë©‹ì§€ì„¸ìš”! ì „ê³µ ë¶„ì•¼ê°€ ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”? ë°•ì‚¬ê³¼ì •ì—ì„œ ì–´ë–¤ ì—°êµ¬ë¥¼ í•˜ê³  ìˆëŠ”ì§€ ê¶ê¸ˆí•˜ë„¤ìš”.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 134, 'total_tokens': 185, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d28bcae782', 'finish_reason': 'stop', 'logprobs': None}, id='run-705987ad-6fe1-44d3-97b2-0ba0f9dc7898-0', usage_metadata={'input_tokens': 134, 'output_tokens': 51, 'total_tokens': 185, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚´ ì·¨ë¯¸ëŠ” í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™í•˜ëŠ”ê±°ê³ , ë¼ì§€ê³ ê¸°ë¥¼ ì œì¼ì¢‹ì•„í•´', additional_kwargs={}, response_metadata={}, id='912d0ad6-6b6a-47ba-8f71-0ca21ce7980d'),\n",
       "  AIMessage(content='í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ì‹œëŠ”êµ°ìš”! ê±´ê°•ì„ ì˜ ì±™ê¸°ì‹œëŠ” ê²ƒ ê°™ì•„ ì¢‹ë„¤ìš”. ê·¸ë¦¬ê³  ë¼ì§€ê³ ê¸°ë¥¼ ì¢‹ì•„í•˜ì‹ ë‹¤ê³  í•˜ì…¨ìœ¼ë‹ˆ, í˜¹ì‹œ ì‚¼ê²¹ì‚´ ê°™ì€ ìš”ë¦¬ë¥¼ ì¦ê¸°ì‹œë‚˜ìš”? ë§›ìˆëŠ” ìŒì‹ê³¼ ìš´ë™ì˜ ì¡°í•©ì´ë¼ë‹ˆ ë©‹ì§€ë„¤ìš”!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 239, 'total_tokens': 309, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-04d7f469-305a-4f23-8113-726b29e897a6-0', usage_metadata={'input_tokens': 239, 'output_tokens': 70, 'total_tokens': 309, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚˜ì— ëŒ€í•´ì„œ ì•Œê³ ìˆëŠ”ê²Œ ìˆì–´?', additional_kwargs={}, response_metadata={}, id='d681c693-ad25-4d3f-8e31-1e57f0f3377c'),\n",
       "  AIMessage(content='ë¬¼ë¡ ì´ì£ , ì°½ìš°ë‹˜! ì°½ìš°ë‹˜ì€ 30ì‚´ì´ê³ , ë¶€ì‚°ëŒ€í•™êµì—ì„œ ë°•ì‚¬ê³¼ì •ì„ í•˜ê³  ê³„ì‹œë©°, ì·¨ë¯¸ëŠ” í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™í•˜ëŠ” ê²ƒì´ê³ , ë¼ì§€ê³ ê¸°ë¥¼ ì¢‹ì•„í•˜ì‹ ë‹¤ê³  í•˜ì…¨ìŠµë‹ˆë‹¤. í˜¹ì‹œ ë” ì¶”ê°€í•˜ê³  ì‹¶ì€ ì •ë³´ê°€ ìˆê±°ë‚˜ ë‹¤ë¥¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 335, 'total_tokens': 412, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-94192bdd-748d-4f0c-b49e-cc08a6c52aa5-0', usage_metadata={'input_tokens': 335, 'output_tokens': 77, 'total_tokens': 412, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ì•„ë‹ˆì•¼. ì˜ëª»ë§í–ˆì–´. ë‚´ì´ë¦„ì€ ê¹€í˜¸ì›ì´ê³ , ë‚˜ì´ëŠ” 54ì‚´ì´ì•¼. í˜„ì¬ ìŠ¤ë§ˆíŠ¸ì— íˆ¬ì—  ëŒ€í‘œë¡œ ì¼í•˜ê³ ìˆì–´.', additional_kwargs={}, response_metadata={}, id='c5c28aad-1572-4926-a997-5193506ee5fb'),\n",
       "  AIMessage(content='ì•Œê² ìŠµë‹ˆë‹¤, í˜¸ì›ë‹˜! ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤. ìŠ¤ë§ˆíŠ¸ì— íˆ¬ì— ì˜ ëŒ€í‘œë¡œ ì¼í•˜ê³  ê³„ì‹œë‹¤ë‹ˆ ì¸ìƒì ì´ë„¤ìš”. í˜¹ì‹œ íšŒì‚¬ì—ì„œëŠ” ì–´ë–¤ ë¶„ì•¼ì— ì§‘ì¤‘í•˜ê³  ê³„ì‹ ê°€ìš”? ê¶ê¸ˆí•©ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 460, 'total_tokens': 511, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_b7d65f1a5b', 'finish_reason': 'stop', 'logprobs': None}, id='run-033a60ae-7899-442b-8ea3-62f0aca2a18a-0', usage_metadata={'input_tokens': 460, 'output_tokens': 51, 'total_tokens': 511, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content='ë‚˜ì— ëŒ€í•´ì„œ ì•Œê³ ìˆëŠ”ê²Œ ìˆì–´?', additional_kwargs={}, response_metadata={}, id='3a9ee7da-849a-49dd-8632-84010b167a71'),\n",
       "  AIMessage(content='ë„¤, í˜¸ì›ë‹˜ì— ëŒ€í•´ ì•Œê³  ìˆëŠ” ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: í˜¸ì›ë‹˜ì€ 54ì‚´ì´ì‹œê³ , ìŠ¤ë§ˆíŠ¸ì— íˆ¬ì— ì˜ ëŒ€í‘œë¡œ ì¼í•˜ê³  ê³„ì‹­ë‹ˆë‹¤. ì·¨ë¯¸ëŠ” í—¬ìŠ¤ì¥ì—ì„œ ìš´ë™í•˜ëŠ” ê²ƒì´ê³ , ì¢‹ì•„í•˜ëŠ” ìŒì‹ì€ ë¼ì§€ê³ ê¸°ì…ë‹ˆë‹¤. í˜¹ì‹œ ë” ì¶”ê°€í•˜ì‹œê±°ë‚˜ ìˆ˜ì •í•  ì‚¬í•­ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 83, 'prompt_tokens': 529, 'total_tokens': 612, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_5f20662549', 'finish_reason': 'stop', 'logprobs': None}, id='run-e9a8e500-a28b-4aea-a68b-8be04943f2d5-0', usage_metadata={'input_tokens': 529, 'output_tokens': 83, 'total_tokens': 612, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":\"ë‚˜ì— ëŒ€í•´ì„œ ì•Œê³ ìˆëŠ”ê²Œ ìˆì–´?\"}, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
