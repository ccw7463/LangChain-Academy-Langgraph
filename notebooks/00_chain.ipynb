{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì°¸ê³ \n",
    "- `@trace_function()` ì€ ì œê°€ ìì²´ì ìœ¼ë¡œ ì‘ì„±í•œ ë°ì½”ë ˆì´í„°ì…ë‹ˆë‹¤. ê²½ë¡œëŠ” `utils/util.py` ì…ë‹ˆë‹¤.\n",
    "\n",
    "- ë­ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª©ë¡ì€ `modules/base.py` ì— ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.base import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë‹µë³€ ìƒì„±í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='ì•ˆë…•í•˜ì„¸ìš”', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ë„¤~ ì•ˆë…•í•˜ì„¸ìš”. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ê³ ë˜ì— ëŒ€í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”~', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [HumanMessage(content=f\"ì•ˆë…•í•˜ì„¸ìš”\"),\n",
    "            AIMessage(content=f\"ë„¤~ ì•ˆë…•í•˜ì„¸ìš”. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\"),\n",
    "            HumanMessage(content=f\"ê³ ë˜ì— ëŒ€í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”~\")]\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. OpenAI ëª¨ë¸ ì‚¬ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê³ ë˜ëŠ” í•´ì–‘ í¬ìœ ë¥˜ì˜ ì¼ì¢…ìœ¼ë¡œ, ì£¼ë¡œ ë°”ë‹¤ì—ì„œ ìƒí™œí•©ë‹ˆë‹¤. ê³ ë˜ëŠ” ë‹¤ì–‘í•œ ì¢…ë¥˜ê°€ ìˆìœ¼ë©°, ê·¸ í¬ê¸°ì™€ íŠ¹ì„±ì— ë”°ë¼ ì—¬ëŸ¬ ë²”ì£¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸° ëª‡ ê°€ì§€ ì£¼ìš” íŠ¹ì§•ì„ ì•Œë ¤ë“œë¦´ê²Œìš”:\n",
      "\n",
      "1. **í¬ê¸°**: ê³ ë˜ëŠ” ì„¸ê³„ì—ì„œ ê°€ì¥ í° ë™ë¬¼ ì¤‘ í•˜ë‚˜ë¡œ, ëŒ€ì™•ê³ ë˜(ë¸”ë£¨ì›¨ì¼)ëŠ” ì§€êµ¬ìƒì—ì„œ ê°€ì¥ í° ë™ë¬¼ì…ë‹ˆë‹¤. ëŒ€ì™•ê³ ë˜ëŠ” ê¸¸ì´ê°€ ìµœëŒ€ 30ë¯¸í„°ì— ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ì¢…ë¥˜**: ê³ ë˜ëŠ” ë‘ ê°€ì§€ ì£¼ìš” ê·¸ë£¹ìœ¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤: ìˆ˜ì—¼ê³ ë˜ì™€ ì´ë¹¨ê³ ë˜ì…ë‹ˆë‹¤. \n",
      "   - ìˆ˜ì—¼ê³ ë˜ëŠ” ìˆ˜ì—¼íŒì„ ì´ìš©í•´ í”Œë‘í¬í†¤ê³¼ ì‘ì€ ë¬¼ê³ ê¸°ë¥¼ ê±¸ëŸ¬ ë¨¹ìŠµë‹ˆë‹¤. ëŒ€ì™•ê³ ë˜, í˜¹ë“±ê³ ë˜ ë“±ì´ ì—¬ê¸°ì— ì†í•©ë‹ˆë‹¤.\n",
      "   - ì´ë¹¨ê³ ë˜ëŠ” ì´ë¹¨ì„ ê°€ì§€ê³  ìˆì–´ ë¬¼ê³ ê¸°ë‚˜ ì˜¤ì§•ì–´ ë“±ì„ ì‚¬ëƒ¥í•©ë‹ˆë‹¤. ëŒê³ ë˜, í–¥ìœ ê³ ë˜ ë“±ì´ ì—¬ê¸°ì— ì†í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **í˜¸í¡**: ê³ ë˜ëŠ” í¬ìœ ë¥˜ì´ê¸° ë•Œë¬¸ì— ì•„ê°€ë¯¸ê°€ ì•„ë‹Œ íë¡œ í˜¸í¡í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ ìˆ˜ë©´ ìœ„ë¡œ ì˜¬ë¼ì™€ ê³µê¸°ë¥¼ ë“¤ì´ë§ˆì…”ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "4. **ì§€ëŠ¥**: ê³ ë˜ëŠ” ë†’ì€ ì§€ëŠ¥ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, íŠ¹íˆ ëŒê³ ë˜ëŠ” ë§¤ìš° ì‚¬íšŒì ì´ê³  ë³µì¡í•œ ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ì„ ê°€ì§€ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "5. **ì†Œë¦¬**: ê³ ë˜ëŠ” ì˜ì‚¬ì†Œí†µì„ ìœ„í•´ ì†Œë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. íŠ¹íˆ, ìˆ˜ì—¼ê³ ë˜ëŠ” 'ê³ ë˜ ë…¸ë˜'ë¼ê³  ë¶ˆë¦¬ëŠ” ì†Œë¦¬ë¥¼ ë‚´ë©°, ì´ëŠ” ì—¬ëŸ¬ ê°€ì§€ ëª©ì (ì˜ˆ: ì§ì§“ê¸°, ê¸¸ ì°¾ê¸° ë“±)ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "6. **ë³´ì „ ìƒíƒœ**: ë§ì€ ê³ ë˜ ì¢…ë“¤ì´ ì¸ê°„ì˜ í™œë™(ì˜ˆ: ê³ ë˜ì¡ì´, í•´ì–‘ ì˜¤ì—¼ ë“±)ìœ¼ë¡œ ì¸í•´ ìœ„í˜‘ë°›ê³  ìˆìœ¼ë©°, ì—¬ëŸ¬ ì¢…ì´ ë©¸ì¢… ìœ„ê¸°ì— ì²˜í•´ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ì „ ì„¸ê³„ì ìœ¼ë¡œ ê³ ë˜ ë³´í˜¸ ë…¸ë ¥ì´ ì´ë£¨ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê³ ë˜ì— ê´€í•´ ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. HuggingFace ëª¨ë¸ ì‚¬ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain_huggingface import ChatHuggingFace\n",
    "\n",
    "llm_endpoint = HuggingFaceEndpoint(\n",
    "    endpoint_url=\"http://192.168.1.21:17011\", # Endpoint ì£¼ì†Œ (TGI ì‚¬ìš©)\n",
    "    huggingfacehub_api_token=os.getenv(\"HF_API_TOKEN\"), # HuggingFace API í† í°\n",
    "    max_new_tokens=4096,\n",
    "    top_k=1,\n",
    "    top_p=0.001,\n",
    "    temperature=0.001,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "\n",
    "huggingface_llm = ChatHuggingFace(\n",
    "    llm=llm_endpoint,\n",
    "    # model_id=\"beomi/gemma-ko-2b\", # ì‚¬ìš©í•  HuggingFace ëª¨ë¸ ì´ë¦„\n",
    "    model_id=\"google/gemma-2-2b-it\",\n",
    "    stream_mode=True\n",
    ").bind(max_tokens=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface_llm.tokenizer.chat_template = \"{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\\n' + message['content'] | trim + '<end_of_turn>\\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n'}}{% endif %}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê³ ë˜ì— ëŒ€í•´ ì•Œë ¤ë“œë¦´ê²Œìš”! ğŸ˜Š\n",
      "\n",
      "**ê³ ë˜ëŠ” ì„¸ê³„ì—ì„œ ê°€ì¥ í° ìœ¡ìƒ ë™ë¬¼ ì¤‘ í•˜ë‚˜ì´ë©°, ìƒì§•ì ì¸ ì¡´ì¬ì´ë‹¤.** ğŸŒŠğŸ³\n",
      "\n",
      "ê³ ë˜ì˜ ì¢…ë¥˜ì—ëŠ” \n",
      "\n",
      "* **ëŠ™ì€ ê³ ë˜:** ì‹¬ì˜¤í•˜ê³  ì¡°ìš©í•œ ì¡´ì¬ë¡œ, ì˜¤ëŠ˜ì˜ ì—­ì‚¬ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” ê²ƒì„ ìƒìƒí•´ ë³´ì„¸ìš”.\n",
      "* **ì–´ë¦° ê³ ë˜:** **ì–´ë ¤ìš´ ì§€ì  ê·¸ë¦¼ìì™€ í•¨ê»˜í•˜ëŠ” ì´ì•¼ê¸°**, ì–´ë¦° ì·¨ì¹¨ ì‹œê°„ì— ê¿ˆê¿”ë³´ê³  ì‹¶ì–´ í•  ë•Œ, ì‹œëŒ€ì˜ ë¹›ì„ ì°¾ì•„ë“œë¦´ ìˆ˜ ìˆì–´.\n",
      "\n",
      "ê°ê°ì˜ ì¢…ë¥˜ë“¤ì€ ì„œë¡œ ë‹¤ë¥¸ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆê³ , ì„œë¡œ ë‹¤ë¥¸ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì¢€ ë” ìì„¸í•œ ë‚´ìš©ì„ ì•Œê³  ì‹¶ìœ¼ì‹œë©´, ì–´ë–¤ ì¢…ë¥˜ì˜ ê³ ë˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ì›í•˜ì‹œë‚˜ìš”? ì˜ˆë¥¼ ë“¤ì–´:\n",
      "\n",
      "* **ì–´ë–¤ ì¢…ë¥˜ì˜ ê³ ë˜ê°€ ì–´ë–¤ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆë‚˜ìš”?**\n",
      "* **íŠ¹ë³„í•œ ìƒí™©ì´ë‚˜ ì§€ì—­ì ìœ¼ë¡œ í° ê³ ë˜ ì´ì•¼ê¸°ê°€ ìˆë‚˜ìš”?**\n",
      "* **ê³ ë˜ì†ì— ì‚´ê³  ìˆë˜ ì›ìˆ­ì´ëŠ” ì–´ì©” ìˆ˜ ì—†ì„ê¹Œìš”?** \n",
      "\n",
      "\n",
      "\n",
      " ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ì£¼ì„¸ìš”. ğŸ³ğŸŒŠ â¤ï¸ \n"
     ]
    }
   ],
   "source": [
    "for chunk in huggingface_llm.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
