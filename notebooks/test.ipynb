{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from functools import wraps\n",
    "import sys\n",
    "import argparse\n",
    "import random\n",
    "from operator import add\n",
    "from dataclasses import dataclass\n",
    "from typing import Literal, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Image, display\n",
    "from ml_collections import ConfigDict\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage, RemoveMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import AnyMessage, RemoveMessage, trim_messages\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.store.base import BaseStore\n",
    "from pydantic import BaseModel, field_validator, ValidationError\n",
    "import uuid\n",
    "# TODO 지워야함 나중에 ==============================\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# =================================================\n",
    "\n",
    "prompt_config = ConfigDict()\n",
    "prompt_config.answer_prompt = \"\"\"당신은 [사용자 정보]를 통해 답변하는 유용한 챗봇입니다.\n",
    "[사용자 정보]:\n",
    "{memory}\"\"\"\n",
    "prompt_config.create_memory_prompt =\"\"\"당신은 사용자의 응답을 개인화하기 위해 사용자에 대한 정보를 수집하고 있습니다.\n",
    "\n",
    "[현재 사용자 정보]:\n",
    "{memory}\n",
    "\n",
    "지침:\n",
    "1. 아래의 채팅 기록을 주의 깊게 검토하세요.\n",
    "2. 사용자에 대한 새로운 정보를 식별하세요. 예를 들면:\n",
    "   - 개인 정보 (이름, 위치 등)\n",
    "   - 선호 사항 (좋아하는 것, 싫어하는 것 등)\n",
    "   - 관심사와 취미\n",
    "   - 과거 경험\n",
    "   - 목표나 미래 계획   \n",
    "3. 새로운 정보를 기존 메모리와 병합하세요.\n",
    "4. 메모리는 명확한 불릿 리스트 형식으로 작성하세요.\n",
    "5. 새로운 정보가 기존 메모리와 충돌할 경우, 가장 최근 정보를 유지하세요.\n",
    "6. 만약 새로운 정보가 없다면 [현재 사용자 정보] 부분의 내용을 그대로 출력하세요.\n",
    "7. 기존 정보를 유지할경우 [현재 사용자 정보] 부분의 내용을 그대로 출력하세요.\n",
    "\n",
    "기억하세요: 사용자가 직접적으로 언급한 사실적인 정보만 포함해야 합니다. 추측이나 추론을 하지 마세요.\n",
    "\n",
    "아래의 채팅 기록을 바탕으로 사용자 정보를 업데이트하세요:\n",
    "\n",
    "출력 양식은 반드시 아래를 따르세요.\n",
    "\n",
    "- 정보 종류 : 정보 내용\n",
    "- 정보 종류 : 정보 내용\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "def trace_function(enable_print=True, only_func_name=False):\n",
    "    def wrapper(func):\n",
    "        @wraps(func)\n",
    "        def wrapped(*args, **kwargs):\n",
    "            if enable_print:\n",
    "                if only_func_name:\n",
    "                    print(f\"    - Passing Through [{func.__name__}] ..{RESET}\")\n",
    "                else:\n",
    "                    print(f\"    - Passing Through [{func.__name__}] ..{RESET}\")\n",
    "                    print(f\"{RED}#### [Input State]{RESET}\")\n",
    "                    print(f\"  args: {args}\")\n",
    "                    print(f\"  kwargs: {kwargs}\")\n",
    "            result = func(*args, **kwargs)  # 원본 함수 호출\n",
    "            if enable_print:\n",
    "                if only_func_name:\n",
    "                    pass\n",
    "                else:\n",
    "                    print(f\"\\n{BLUE}#### [Output State]{RESET}\")\n",
    "                    print(f\"  result: {result}\")\n",
    "            return result\n",
    "        return wrapped\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "RESET = \"\\033[0m\"        # Reset to default\n",
    "RED = \"\\033[91m\"         # Bright Red\n",
    "BLUE = \"\\033[94m\"        # Bright Blue\n",
    "GREEN = \"\\033[92m\"        # Bright Green\n",
    "YELLOW = \"\\033[93m\"       # Bright Yellow\n",
    "PINK = \"\\033[95m\"         # Bright Pink\n",
    "\n",
    "class ToolConversation:\n",
    "    def __init__(self):\n",
    "        self.system_prompt = \"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n",
    "        self.tools = [self._tool_divide, self._tool_add, self._tool_multiply]\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o\") # TODO 허깅페이스 받도록 설정\n",
    "        self.llm_with_tools = self.llm.bind_tools(self.tools, parallel_tool_calls=False)\n",
    "        self._build_graph()\n",
    "\n",
    "    def __call__(self,\n",
    "                 messages):\n",
    "        return self._call_graph(messages)\n",
    "\n",
    "    def _call_graph(self, \n",
    "                    messages):\n",
    "        \"\"\"\n",
    "            Des:\n",
    "                그래프 호출 함수\n",
    "        \"\"\"\n",
    "        return self.graph.invoke({\"messages\": messages})\n",
    "\n",
    "    def _build_graph(self):\n",
    "        \"\"\"\n",
    "            Des:\n",
    "                그래프 생성함수\n",
    "        \"\"\"\n",
    "        builder = StateGraph(MessagesState)\n",
    "        builder.add_node(\"_node_assistant\", self._node_assistant)\n",
    "        builder.add_node(\"tools\", ToolNode(self.tools))\n",
    "        builder.add_edge(START, \"_node_assistant\")\n",
    "        builder.add_conditional_edges(\"_node_assistant\", tools_condition)\n",
    "        builder.add_edge(\"tools\", \"_node_assistant\")\n",
    "        self.graph = builder.compile()\n",
    "\n",
    "    @trace_function(enable_print=True, only_func_name=True)\n",
    "    def _node_assistant(self, state:MessagesState):\n",
    "        return {\"messages\": [self.llm_with_tools.invoke([SystemMessage(content=self.system_prompt)] + state[\"messages\"])]}\n",
    "\n",
    "    @trace_function(enable_print=True, only_func_name=True)\n",
    "    def _tool_multiply(self,\n",
    "                       a: int, \n",
    "                       b: int) -> int:\n",
    "        \"\"\"Multiply a and b.\n",
    "\n",
    "        Args:\n",
    "            a: first int\n",
    "            b: second int\n",
    "        \"\"\"\n",
    "        return a * b\n",
    "\n",
    "    @trace_function(enable_print=True, only_func_name=True)\n",
    "    def _tool_add(self,\n",
    "                  a: int, \n",
    "                  b: int) -> int:\n",
    "        \"\"\"Adds a and b.\n",
    "\n",
    "        Args:\n",
    "            a: first int\n",
    "            b: second int\n",
    "        \"\"\"\n",
    "        return a + b\n",
    "\n",
    "    @trace_function(enable_print=True, only_func_name=True)\n",
    "    def _tool_divide(self,\n",
    "                     a: int, \n",
    "                     b: int) -> float:\n",
    "        \"\"\"Divide a and b.\n",
    "\n",
    "        Args:\n",
    "            a: first int\n",
    "            b: second int\n",
    "        \"\"\"\n",
    "        return a / b\n",
    "    \n",
    "    \n",
    "class ConversationTest:\n",
    "    def __init__(self):\n",
    "        self.LIMIT_LENGTH = 6\n",
    "        self.ShortTermMemory = MemorySaver()\n",
    "        self.LongTermMemory = InMemoryStore()\n",
    "        self.system_prompt = \"당신은 사용자 요청에 답변하는 유용한 챗봇입니다.\"\n",
    "        self.llm = ChatOpenAI(model=\"gpt-4o\") # TODO 허깅페이스 받도록 설정\n",
    "        self._set_config()\n",
    "        self._build_graph()\n",
    "\n",
    "    def __call__(self,\n",
    "                 messages:list[str]):\n",
    "        return self._call_graph(messages)\n",
    "\n",
    "    def _call_graph(self, \n",
    "                    messages):\n",
    "        \"\"\"\n",
    "            Des:\n",
    "                그래프 호출 함수\n",
    "        \"\"\"\n",
    "        return self.graph.invoke({\"messages\": messages}, config=self.config)\n",
    "        \n",
    "    def _build_graph(self):\n",
    "        \"\"\"\n",
    "            Des:\n",
    "                그래프 생성함수\n",
    "        \"\"\"\n",
    "        builder = StateGraph(MessagesState)\n",
    "        builder.add_node(\"_node_answer\", self._node_answer)\n",
    "        builder.add_node(\"_node_write_memory\", self._node_write_memory)\n",
    "        builder.add_node(\"_node_optimize_memory\", self._node_optimize_memory)\n",
    "        builder.add_edge(START, \"_node_answer\")\n",
    "        builder.add_edge(\"_node_answer\", \"_node_write_memory\")\n",
    "        builder.add_conditional_edges(\"_node_write_memory\", self._check_memory_length)\n",
    "        builder.add_edge(\"_node_optimize_memory\", END)\n",
    "        self.graph = builder.compile(checkpointer=self.ShortTermMemory,\n",
    "                                     store=self.LongTermMemory)\n",
    "\n",
    "    @trace_function(enable_print=True, only_func_name=True)\n",
    "    def _node_answer(self, \n",
    "                    state: MessagesState, \n",
    "                    config: RunnableConfig,\n",
    "                    store: BaseStore):\n",
    "        \"\"\"\n",
    "            Des:\n",
    "                사용자 메시지를 인식하고, 답변을 생성하는 노드\n",
    "        \"\"\"\n",
    "        namespace = (\"memories\", config[\"configurable\"][\"user_id\"])\n",
    "        key = \"chat_user_memory\"\n",
    "        memory = self._get_memory(namespace=namespace, \n",
    "                                  key=key, \n",
    "                                  store=store)\n",
    "        system_message = prompt_config.answer_prompt.format(memory=memory)\n",
    "        prompt = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "        # print(f\"{PINK}\\n{prompt[0].content}\\n{RESET}\")\n",
    "        response = self.llm.invoke(prompt)\n",
    "        return {\"messages\": response}\n",
    "\n",
    "    @trace_function(enable_print=True, only_func_name=True)\n",
    "    def _node_write_memory(self,\n",
    "                          state: MessagesState, \n",
    "                          config: RunnableConfig, \n",
    "                          store: BaseStore):\n",
    "        \"\"\"\n",
    "            Des:\n",
    "                사용자 메시지를 인식하고, 개인정보로 저장하는 노드\n",
    "        \"\"\"\n",
    "        namespace = (\"memories\", config[\"configurable\"][\"user_id\"])\n",
    "        key = \"chat_user_memory\"\n",
    "        memory = self._get_memory(namespace=namespace, \n",
    "                                  key=key, \n",
    "                                  store=store)\n",
    "        system_message = prompt_config.create_memory_prompt.format(memory=memory)\n",
    "        prompt = [SystemMessage(content=system_message)]+state[\"messages\"]\n",
    "        response = self.llm.invoke(prompt)\n",
    "        store.put(namespace=namespace, \n",
    "                  key=key, \n",
    "                  value={\"memory\":response.content})\n",
    "    \n",
    "    @trace_function(enable_print=True, only_func_name=True)\n",
    "    def _node_optimize_memory(self,\n",
    "                              state: MessagesState):\n",
    "        \"\"\"\n",
    "            Des:\n",
    "                메모리 최적화 함수\n",
    "        \"\"\"\n",
    "        delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:self.LIMIT_LENGTH//2]]\n",
    "        return {\"messages\": delete_messages}\n",
    "    \n",
    "    def _generate_session_id(self):\n",
    "        session_id = str(uuid.uuid4())\n",
    "        return session_id\n",
    "        \n",
    "    def _set_config(self,\n",
    "                    session_id:str=\"test_session_id\",\n",
    "                    user_id:str=\"test_user_id\"):\n",
    "        session_id = self._generate_session_id()\n",
    "        self.config = {\"configurable\": {\"thread_id\": session_id,\n",
    "                                        \"user_id\": user_id}}\n",
    "\n",
    "    def _check_memory_length(self,\n",
    "                             state: MessagesState):\n",
    "        \"\"\"\n",
    "            Des:\n",
    "                메모리 길이 체크 함수\n",
    "        \"\"\"\n",
    "        if len(state[\"messages\"]) > self.LIMIT_LENGTH:\n",
    "            return \"_node_optimize_memory\"\n",
    "        else:\n",
    "            return END\n",
    "    \n",
    "    def _get_memory(self,\n",
    "                    namespace, \n",
    "                    key,\n",
    "                    store:BaseStore):\n",
    "        \"\"\"\n",
    "            Des:\n",
    "                현재 저장된 사용자 정보를 가져오는 함수\n",
    "        \"\"\"\n",
    "        existing_memory = store.get(namespace=namespace,\n",
    "                                    key=key)\n",
    "        return existing_memory.value.get('memory') if existing_memory else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m========================================\u001b[0m\n",
      "\u001b[92m [Langgraph 기반 툴 테스트를 시작합니다.]\u001b[0m\n",
      "\u001b[92m========================================\u001b[0m\n",
      " \u001b[93m요청 메시지 : Add 3 and 4. Multiply the output by 2. Divide the output by 5\u001b[0m\n",
      "    - Passing Through [_node_assistant] ..\u001b[0m\n",
      "    - Passing Through [_tool_add] ..\u001b[0m\n",
      "    - Passing Through [_node_assistant] ..\u001b[0m\n",
      "    - Passing Through [_tool_multiply] ..\u001b[0m\n",
      "    - Passing Through [_node_assistant] ..\u001b[0m\n",
      "    - Passing Through [_tool_divide] ..\u001b[0m\n",
      "    - Passing Through [_node_assistant] ..\u001b[0m\n",
      "\u001b[92m========================================\u001b[0m\n",
      "\u001b[92m        [대화가 종료되었습니다.]\u001b[0m\n",
      "\u001b[92m========================================\u001b[0m\n",
      "\u001b[94m중간 결과 : 7\u001b[94m\n",
      "\u001b[94m중간 결과 : 14\u001b[94m\n",
      "\u001b[94m중간 결과 : 2.8\u001b[94m\n",
      "\u001b[94m최종 답변 메시지 : The result of adding 3 and 4, multiplying the result by 2, and then dividing by 5 is 2.8.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tool_conversation = ToolConversation()\n",
    "print(f\"{GREEN}========================================{RESET}\")\n",
    "print(f\"{GREEN} [Langgraph 기반 툴 테스트를 시작합니다.]{RESET}\")\n",
    "print(f\"{GREEN}========================================{RESET}\")\n",
    "messages = \"Add 3 and 4. Multiply the output by 2. Divide the output by 5\"\n",
    "print(f\" {YELLOW}요청 메시지 : {messages}{RESET}\")\n",
    "messages = tool_conversation(messages)\n",
    "print(f\"{GREEN}========================================{RESET}\")\n",
    "print(f\"{GREEN}        [대화가 종료되었습니다.]{RESET}\")\n",
    "print(f\"{GREEN}========================================{RESET}\")\n",
    "for message in messages['messages']:\n",
    "    if type(message).__name__ == \"ToolMessage\":\n",
    "        print(f\"{BLUE}중간 결과 : {message.content}{RESET}\")\n",
    "print(f\"{BLUE}최종 답변 메시지 : {messages['messages'][-1].content}{RESET}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Content: Add 3 and 4. Multiply the output by 2. Divide the output by 5\n",
      "Type: HumanMessage\n",
      "Message Content: \n",
      "Type: AIMessage\n",
      "Message Content: 7\n",
      "Type: ToolMessage\n",
      "Message Content: \n",
      "Type: AIMessage\n",
      "Message Content: 14\n",
      "Type: ToolMessage\n",
      "Message Content: \n",
      "Type: AIMessage\n",
      "Message Content: 2.8\n",
      "Type: ToolMessage\n",
      "Message Content: The result of adding 3 and 4, multiplying the result by 2, and then dividing by 5 is 2.8.\n",
      "Type: AIMessage\n"
     ]
    }
   ],
   "source": [
    "# 각 메시지의 타입 확인\n",
    "for message in messages['messages']:\n",
    "    print(f\"Message Content: {message.content}\")\n",
    "    print(f\"Type: {type(message).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m========================================\u001b[0m\n",
      "\u001b[92m[Langgraph 기반 채팅 테스트를 시작합니다.]\u001b[0m\n",
      "\u001b[92m========================================\u001b[0m\n",
      " \u001b[93m요청 메시지 : 안녕하세요, 저는 홍길동이라고 합니다.\u001b[0m\n",
      "    - Passing Through [_node_answer] ..\u001b[0m\n",
      "    - Passing Through [_node_write_memory] ..\u001b[0m\n",
      " \u001b[94m답변 메시지 : 안녕하세요, 홍길동님! 만나서 반갑습니다. 오늘 어떻게 도와드릴까요?\u001b[0m\n",
      "\n",
      " \u001b[93m요청 메시지 : 저는 올해 25살이고, 한국대학교에서 재학중이에요.\u001b[0m\n",
      "    - Passing Through [_node_answer] ..\u001b[0m\n",
      "    - Passing Through [_node_write_memory] ..\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "conversation = ConversationTest()\n",
    "print(f\"{GREEN}========================================{RESET}\")\n",
    "print(f\"{GREEN}[Langgraph 기반 채팅 테스트를 시작합니다.]{RESET}\")\n",
    "print(f\"{GREEN}========================================{RESET}\")\n",
    "messages_lst = [\"안녕하세요, 저는 홍길동이라고 합니다.\",\n",
    "                \"저는 올해 25살이고, 한국대학교에서 재학중이에요.\",\n",
    "                \"제 전공은 인공지능이고 요즘 LLM 분야에 관심이 많아요.\",\n",
    "                \"제가 제일 좋아하는 음식은 돼지고기이고, 싫어하는 음식은 딱히없어요.\",\n",
    "                \"저에 대해 아시는게 있나요?\"]\n",
    "\n",
    "for message in messages_lst:\n",
    "    print(f\" {YELLOW}요청 메시지 : {message}{RESET}\")\n",
    "    convs = conversation(message)\n",
    "    print(f\" {BLUE}답변 메시지 : {convs['messages'][-1].content}{RESET}\\n\")\n",
    "print(f\"{GREEN}========================================{RESET}\")\n",
    "print(f\"{GREEN}        [대화가 종료되었습니다.]{RESET}\")\n",
    "print(f\"{GREEN}========================================{RESET}\")\n",
    "\n",
    "print(\"사용자와의 대화로부터 추출한 정보는 다음과 같습니다.\\n\")\n",
    "namespace = (\"memories\", conversation.config[\"configurable\"][\"user_id\"])\n",
    "key = \"chat_user_memory\"\n",
    "memory = conversation._get_memory(namespace=namespace, \n",
    "                                  key=key, \n",
    "                                  store=conversation.LongTermMemory)\n",
    "print(memory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
